{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e01", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       ns['metadata']['name'] AS namespace\nORDER BY namespace", "tokens": {"prompt": 17341, "output": 60, "total": 17401}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       ns['metadata']['name'] AS namespace\nORDER BY namespace", "rows": 34}, "metrics": {"attempts": 1, "latency_ms": 14215, "total_tokens": 17401, "total_prompt_tokens": 17341, "total_output_tokens": 60}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e02", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster_name, COUNT(n) AS namespace_count\nORDER BY namespace_count DESC;", "tokens": {"prompt": 17343, "output": 80, "total": 17423}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster_name, COUNT(n) AS namespace_count\nORDER BY namespace_count DESC;", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 4413, "total_tokens": 17423, "total_prompt_tokens": 17343, "total_output_tokens": 80}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e03", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod_name,\n       p['status']['phase'] AS phase,\n       p['metadata']['uid'] AS pod_uid\nORDER BY pod_name;", "tokens": {"prompt": 17342, "output": 127, "total": 17469}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod_name,\n       p['status']['phase'] AS phase,\n       p['metadata']['uid'] AS pod_uid\nORDER BY pod_name;", "rows": 7}, "metrics": {"attempts": 1, "latency_ms": 2947, "total_tokens": 17469, "total_prompt_tokens": 17342, "total_output_tokens": 127}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e04", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN s['metadata']['name'] AS service_name,\n       s['metadata']['namespace'] AS namespace,\n       s['spec']['type'] AS type,\n       s['spec']['clusterIP'] AS cluster_ip\nORDER BY service_name;", "tokens": {"prompt": 17342, "output": 132, "total": 17474}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN s['metadata']['name'] AS service_name,\n       s['metadata']['namespace'] AS namespace,\n       s['spec']['type'] AS type,\n       s['spec']['clusterIP'] AS cluster_ip\nORDER BY service_name;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 3362, "total_tokens": 17474, "total_prompt_tokens": 17342, "total_output_tokens": 132}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e05", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN i['metadata']['name'] AS ingress_name,\n       i['metadata']['namespace'] AS namespace,\n       i['spec']['ingressClassName'] AS ingress_class,\n       i['metadata']['annotations'] AS annotations,\n       i['metadata']['labels'] AS labels\nORDER BY ingress_name;", "tokens": {"prompt": 17343, "output": 152, "total": 17495}}], "final": {"valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN i['metadata']['name'] AS ingress_name,\n       i['metadata']['namespace'] AS namespace,\n       i['spec']['ingressClassName'] AS ingress_class,\n       i['metadata']['annotations'] AS annotations,\n       i['metadata']['labels'] AS labels\nORDER BY ingress_name;", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 5599, "total_tokens": 17495, "total_prompt_tokens": 17343, "total_output_tokens": 152}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e06", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (es:EndpointSlice)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN es['metadata']['name'] AS endpointSlice,\n       es['metadata']['namespace'] AS namespace,\n       es['addressType'] AS addressType,\n       size(es['endpoints']) AS endpointsCount,\n       size(es['ports']) AS portsCount\nORDER BY endpointSlice;", "tokens": {"prompt": 17343, "output": 141, "total": 17484}}], "final": {"valid": true, "error": null, "cypher": "MATCH (es:EndpointSlice)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN es['metadata']['name'] AS endpointSlice,\n       es['metadata']['namespace'] AS namespace,\n       es['addressType'] AS addressType,\n       size(es['endpoints']) AS endpointsCount,\n       size(es['ports']) AS portsCount\nORDER BY endpointSlice;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 3762, "total_tokens": 17484, "total_prompt_tokens": 17343, "total_output_tokens": 141}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e07", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       n.metadata.name AS node_name\nORDER BY cluster, node_name;", "tokens": {"prompt": 17341, "output": 62, "total": 17403}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       n.metadata.name AS node_name\nORDER BY cluster, node_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 1614, "total_tokens": 17403, "total_prompt_tokens": 17341, "total_output_tokens": 62}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e08", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (sc:StorageClass)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       sc['metadata']['name'] AS storage_class,\n       sc.provisioner AS provisioner,\n       sc.allowVolumeExpansion AS allowVolumeExpansion,\n       sc.reclaimPolicy AS reclaimPolicy,\n       sc.volumeBindingMode AS volumeBindingMode\nORDER BY cluster, storage_class", "tokens": {"prompt": 17342, "output": 107, "total": 17449}}], "final": {"valid": true, "error": null, "cypher": "MATCH (sc:StorageClass)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       sc['metadata']['name'] AS storage_class,\n       sc.provisioner AS provisioner,\n       sc.allowVolumeExpansion AS allowVolumeExpansion,\n       sc.reclaimPolicy AS reclaimPolicy,\n       sc.volumeBindingMode AS volumeBindingMode\nORDER BY cluster, storage_class", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2783, "total_tokens": 17449, "total_prompt_tokens": 17342, "total_output_tokens": 107}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e09", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       pv.metadata.name AS persistent_volume,\n       pv['status']['phase'] AS phase,\n       pv['spec']['storageClassName'] AS storageClassName,\n       pv['spec']['capacity'] AS capacity\nORDER BY cluster, persistent_volume", "tokens": {"prompt": 17342, "output": 124, "total": 17466}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       pv.metadata.name AS persistent_volume,\n       pv['status']['phase'] AS phase,\n       pv['spec']['storageClassName'] AS storageClassName,\n       pv['spec']['capacity'] AS capacity\nORDER BY cluster, persistent_volume", "rows": 17}, "metrics": {"attempts": 1, "latency_ms": 3010, "total_tokens": 17466, "total_prompt_tokens": 17342, "total_output_tokens": 124}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e10", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (sa:ServiceAccount)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN sa['metadata']['name'] AS service_account,\n       sa['metadata']['namespace'] AS namespace,\n       sa['metadata']['uid'] AS uid\nORDER BY service_account;", "tokens": {"prompt": 17343, "output": 134, "total": 17477}}], "final": {"valid": true, "error": null, "cypher": "MATCH (sa:ServiceAccount)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN sa['metadata']['name'] AS service_account,\n       sa['metadata']['namespace'] AS namespace,\n       sa['metadata']['uid'] AS uid\nORDER BY service_account;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 3402, "total_tokens": 17477, "total_prompt_tokens": 17343, "total_output_tokens": 134}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e11", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN d['metadata']['name'] AS deployment,\n       d['metadata']['namespace'] AS namespace\nORDER BY deployment;", "tokens": {"prompt": 17342, "output": 109, "total": 17451}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN d['metadata']['name'] AS deployment,\n       d['metadata']['namespace'] AS namespace\nORDER BY deployment;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 2394, "total_tokens": 17451, "total_prompt_tokens": 17342, "total_output_tokens": 109}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e12", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (rs:ReplicaSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN rs['metadata']['name'] AS replicaset,\n       rs['metadata']['namespace'] AS namespace,\n       rs['metadata']['uid'] AS uid\nORDER BY replicaset;", "tokens": {"prompt": 17343, "output": 122, "total": 17465}}], "final": {"valid": true, "error": null, "cypher": "MATCH (rs:ReplicaSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN rs['metadata']['name'] AS replicaset,\n       rs['metadata']['namespace'] AS namespace,\n       rs['metadata']['uid'] AS uid\nORDER BY replicaset;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 2988, "total_tokens": 17465, "total_prompt_tokens": 17343, "total_output_tokens": 122}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e13", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ss:StatefulSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ss['metadata']['name'] AS statefulset,\n       ss['metadata']['namespace'] AS namespace,\n       ss['metadata']['uid'] AS uid\nORDER BY statefulset;", "tokens": {"prompt": 17344, "output": 117, "total": 17461}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ss:StatefulSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ss['metadata']['name'] AS statefulset,\n       ss['metadata']['namespace'] AS namespace,\n       ss['metadata']['uid'] AS uid\nORDER BY statefulset;", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 2614, "total_tokens": 17461, "total_prompt_tokens": 17344, "total_output_tokens": 117}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e14", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ds:DaemonSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ds['metadata']['name'] AS daemonset,\n       ds['metadata']['namespace'] AS namespace,\n       ds['metadata']['uid'] AS uid\nORDER BY daemonset;", "tokens": {"prompt": 17343, "output": 93, "total": 17436}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ds:DaemonSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ds['metadata']['name'] AS daemonset,\n       ds['metadata']['namespace'] AS namespace,\n       ds['metadata']['uid'] AS uid\nORDER BY daemonset;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5251, "total_tokens": 17436, "total_prompt_tokens": 17343, "total_output_tokens": 93}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e15", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (j:Job)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN j['metadata']['name'] AS job_name,\n       j['metadata']['namespace'] AS namespace,\n       j['metadata']['uid'] AS uid,\n       j['status']['active'] AS active,\n       j['status']['succeeded'] AS succeeded,\n       j['status']['failed'] AS failed\nORDER BY job_name", "tokens": {"prompt": 17342, "output": 158, "total": 17500}}], "final": {"valid": true, "error": null, "cypher": "MATCH (j:Job)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN j['metadata']['name'] AS job_name,\n       j['metadata']['namespace'] AS namespace,\n       j['metadata']['uid'] AS uid,\n       j['status']['active'] AS active,\n       j['status']['succeeded'] AS succeeded,\n       j['status']['failed'] AS failed\nORDER BY job_name", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4062, "total_tokens": 17500, "total_prompt_tokens": 17342, "total_output_tokens": 158}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e16", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['metadata']['namespace'] AS namespace,\n       pvc['status']['phase'] AS phase,\n       pvc['spec']['storageClassName'] AS storageClassName,\n       pvc['spec']['volumeName'] AS volumeName\nORDER BY pvc_name;", "tokens": {"prompt": 17344, "output": 159, "total": 17503}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['metadata']['namespace'] AS namespace,\n       pvc['status']['phase'] AS phase,\n       pvc['spec']['storageClassName'] AS storageClassName,\n       pvc['spec']['volumeName'] AS volumeName\nORDER BY pvc_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4613, "total_tokens": 17503, "total_prompt_tokens": 17344, "total_output_tokens": 159}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e17", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN COUNT(p) AS pod_count", "tokens": {"prompt": 17343, "output": 61, "total": 17404}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN COUNT(p) AS pod_count", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 1928, "total_tokens": 17404, "total_prompt_tokens": 17343, "total_output_tokens": 61}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e18", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (cm:ConfigMap)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN cm['metadata']['name'] AS configmap,\n       cm['metadata']['namespace'] AS namespace\nORDER BY configmap", "tokens": {"prompt": 17343, "output": 81, "total": 17424}}], "final": {"valid": true, "error": null, "cypher": "MATCH (cm:ConfigMap)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN cm['metadata']['name'] AS configmap,\n       cm['metadata']['namespace'] AS namespace\nORDER BY configmap", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 2449, "total_tokens": 17424, "total_prompt_tokens": 17343, "total_output_tokens": 81}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e19", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": false, "error": "Cypher schema validation failed:\n- Invalid relationship: NetworkPolicy -> Namespace via BelongsTo. Allowed: Deployment -> Namespace; PersistentVolumeClaim -> Namespace; ReplicaSet -> Namespace; Job -> Namespace; Container -> Namespace; DaemonSet -> Namespace; Logs -> Namespace; Service -> Namespace; EndpointSlice -> Namespace; Ingress -> Namespace; Pod -> Namespace; ConfigMap -> Namespace; ServiceAccount -> Namespace; StatefulSet -> Namespace. Pattern: (np:NetworkPolicy)-[:BelongsTo]->(ns:Namespace) [rule=script/query/regularQuery/singleQuery/singlePartQ/readingStatement/matchSt/patternWhere/pattern/patternPart/patternElem/patternElemChain/relationshipPattern]\n  Hint: BelongsTo is only allowed as Deployment -> Namespace; PersistentVolumeClaim -> Namespace; ReplicaSet -> Namespace; Job -> Namespace; Container -> Namespace; DaemonSet -> Namespace; Logs -> Namespace; Service -> Namespace; EndpointSlice -> Namespace; Ingress -> Namespace; Pod -> Namespace; ConfigMap -> Namespace; ServiceAccount -> Namespace; StatefulSet -> Namespace. Check direction and node labels.", "cypher": "MATCH (np:NetworkPolicy)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN np['metadata']['name'] AS network_policy,\n       np['metadata']['namespace'] AS namespace,\n       np['metadata']['uid'] AS uid\nORDER BY network_policy;", "tokens": {"prompt": 17343, "output": 142, "total": 17485}}, {"attempt": 2, "valid": true, "error": null, "cypher": "MATCH (np:NetworkPolicy)\nWHERE np['metadata']['namespace'] = 'litmus'\nRETURN np['metadata']['name'] AS network_policy,\n       np['metadata']['namespace'] AS namespace,\n       np['metadata']['uid'] AS uid\nORDER BY network_policy;", "tokens": {"prompt": 17674, "output": 110, "total": 17784}}], "final": {"valid": true, "error": null, "cypher": "MATCH (np:NetworkPolicy)\nWHERE np['metadata']['namespace'] = 'litmus'\nRETURN np['metadata']['name'] AS network_policy,\n       np['metadata']['namespace'] AS namespace,\n       np['metadata']['uid'] AS uid\nORDER BY network_policy;", "rows": 0}, "metrics": {"attempts": 2, "latency_ms": 6427, "total_tokens": 35269, "total_prompt_tokens": 35017, "total_output_tokens": 252}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e20", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ns['metadata']['name'] AS namespace,\n  c['pod_name'] AS pod_name,\n  c['spec']['name'] AS container_name,\n  c['spec']['image'] AS image,\n  c['container_type'] AS container_type,\n  c['metadata']['uid'] AS container_uid\nORDER BY pod_name, container_name;", "tokens": {"prompt": 17342, "output": 131, "total": 17473}}], "final": {"valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ns['metadata']['name'] AS namespace,\n  c['pod_name'] AS pod_name,\n  c['spec']['name'] AS container_name,\n  c['spec']['image'] AS image,\n  c['container_type'] AS container_type,\n  c['metadata']['uid'] AS container_uid\nORDER BY pod_name, container_name;", "rows": 9}, "metrics": {"attempts": 1, "latency_ms": 3212, "total_tokens": 17473, "total_prompt_tokens": 17342, "total_output_tokens": 131}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m01", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(d:Deployment)-[:Manages]->(rs:ReplicaSet)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  d['metadata']['name'] AS deployment,\n  rs['metadata']['name'] AS replica_set\nORDER BY deployment, replica_set", "tokens": {"prompt": 17348, "output": 95, "total": 17443}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(d:Deployment)-[:Manages]->(rs:ReplicaSet)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  d['metadata']['name'] AS deployment,\n  rs['metadata']['name'] AS replica_set\nORDER BY deployment, replica_set", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 3855, "total_tokens": 17443, "total_prompt_tokens": 17348, "total_output_tokens": 95}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m02", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (rs:ReplicaSet)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (rs)-[:Manages]->(p:Pod)\nRETURN\n  rs['metadata']['name'] AS replicaset,\n  collect(DISTINCT p['metadata']['name']) AS managed_pods\nORDER BY replicaset;", "tokens": {"prompt": 17348, "output": 111, "total": 17459}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (rs:ReplicaSet)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (rs)-[:Manages]->(p:Pod)\nRETURN\n  rs['metadata']['name'] AS replicaset,\n  collect(DISTINCT p['metadata']['name']) AS managed_pods\nORDER BY replicaset;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 2552, "total_tokens": 17459, "total_prompt_tokens": 17348, "total_output_tokens": 111}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m03", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ds:DaemonSet)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ds['metadata']['name'] AS daemonset,\n       p['metadata']['name'] AS pod\nORDER BY daemonset, pod", "tokens": {"prompt": 17348, "output": 93, "total": 17441}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ds:DaemonSet)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ds['metadata']['name'] AS daemonset,\n       p['metadata']['name'] AS pod\nORDER BY daemonset, pod", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4078, "total_tokens": 17441, "total_prompt_tokens": 17348, "total_output_tokens": 93}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m04", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:StatefulSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(p:Pod)-[:BelongsTo]->(ns)\nRETURN\n  s.metadata.name AS statefulset,\n  COLLECT(DISTINCT p.metadata.name) AS pods\nORDER BY statefulset;", "tokens": {"prompt": 17349, "output": 139, "total": 17488}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:StatefulSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(p:Pod)-[:BelongsTo]->(ns)\nRETURN\n  s.metadata.name AS statefulset,\n  COLLECT(DISTINCT p.metadata.name) AS pods\nORDER BY statefulset;", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 3171, "total_tokens": 17488, "total_prompt_tokens": 17349, "total_output_tokens": 139}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m05", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(j:Job)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  j['metadata']['name'] AS job_name,\n  p['metadata']['name'] AS pod_name,\n  p['status']['phase'] AS pod_phase\nORDER BY job_name, pod_name;", "tokens": {"prompt": 17347, "output": 173, "total": 17520}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(j:Job)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  j['metadata']['name'] AS job_name,\n  p['metadata']['name'] AS pod_name,\n  p['status']['phase'] AS pod_phase\nORDER BY job_name, pod_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4369, "total_tokens": 17520, "total_prompt_tokens": 17347, "total_output_tokens": 173}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m06", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (s:Service)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nRETURN\n  s['metadata']['name'] AS service,\n  collect(DISTINCT es['metadata']['name']) AS endpoint_slices\nORDER BY service;", "tokens": {"prompt": 17348, "output": 141, "total": 17489}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (s:Service)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nRETURN\n  s['metadata']['name'] AS service,\n  collect(DISTINCT es['metadata']['name']) AS endpoint_slices\nORDER BY service;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 3079, "total_tokens": 17489, "total_prompt_tokens": 17348, "total_output_tokens": 141}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m07", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (s:Service)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (es)<-[:ListedIn]-(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)-[:BelongsTo]->(ns)\nRETURN\n  s['metadata']['name'] AS service,\n  collect(DISTINCT p['metadata']['name']) AS backing_pods\nORDER BY service", "tokens": {"prompt": 17348, "output": 199, "total": 17547}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (s:Service)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (es)<-[:ListedIn]-(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)-[:BelongsTo]->(ns)\nRETURN\n  s['metadata']['name'] AS service,\n  collect(DISTINCT p['metadata']['name']) AS backing_pods\nORDER BY service", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 4427, "total_tokens": 17547, "total_prompt_tokens": 17348, "total_output_tokens": 199}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m08", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:RunsOn]->(n:Node)\nWHERE n['metadata']['name'] = $node\nRETURN p['metadata']['namespace'] AS namespace,\n       p['metadata']['name'] AS pod,\n       p['status']['phase'] AS phase,\n       p['spec']['nodeName'] AS nodeName\nORDER BY namespace, pod;", "tokens": {"prompt": 17344, "output": 127, "total": 17471}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:RunsOn]->(n:Node)\nWHERE n['metadata']['name'] = $node\nRETURN p['metadata']['namespace'] AS namespace,\n       p['metadata']['name'] AS pod,\n       p['status']['phase'] AS phase,\n       p['spec']['nodeName'] AS nodeName\nORDER BY namespace, pod;", "execution_error": "MemgraphError: QueryError: Query execution error: Parameter $node not provided."}, "metrics": {"attempts": 1, "latency_ms": 3656, "total_tokens": 17471, "total_prompt_tokens": 17344, "total_output_tokens": 127}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m09", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nRETURN\n  ns['metadata']['name'] AS namespace,\n  pvc['metadata']['name'] AS pvc,\n  pvc['status']['phase'] AS pvc_phase,\n  pv['metadata']['name'] AS pv,\n  pv['status']['phase'] AS pv_phase\nORDER BY pvc, pv", "tokens": {"prompt": 17351, "output": 169, "total": 17520}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nRETURN\n  ns['metadata']['name'] AS namespace,\n  pvc['metadata']['name'] AS pvc,\n  pvc['status']['phase'] AS pvc_phase,\n  pv['metadata']['name'] AS pv,\n  pv['status']['phase'] AS pv_phase\nORDER BY pvc, pv", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3594, "total_tokens": 17520, "total_prompt_tokens": 17351, "total_output_tokens": 169}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m10", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(p:Pod)\nMATCH (p)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN \n  p['metadata']['name'] AS pod_name,\n  e.reason AS event_reason,\n  e.type AS event_type,\n  e.note AS note,\n  e.eventTime AS event_time,\n  e.deprecatedLastTimestamp AS last_timestamp,\n  e.deprecatedFirstTimestamp AS first_timestamp\nORDER BY coalesce(e.eventTime, e.deprecatedLastTimestamp, e.deprecatedFirstTimestamp) DESC, pod_name ASC", "tokens": {"prompt": 17349, "output": 201, "total": 17550}}], "final": {"valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(p:Pod)\nMATCH (p)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN \n  p['metadata']['name'] AS pod_name,\n  e.reason AS event_reason,\n  e.type AS event_type,\n  e.note AS note,\n  e.eventTime AS event_time,\n  e.deprecatedLastTimestamp AS last_timestamp,\n  e.deprecatedFirstTimestamp AS first_timestamp\nORDER BY coalesce(e.eventTime, e.deprecatedLastTimestamp, e.deprecatedFirstTimestamp) DESC, pod_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5971, "total_tokens": 17550, "total_prompt_tokens": 17349, "total_output_tokens": 201}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m11", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nMATCH (p)-[:RunsOn]->(n:Node)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod,\n       n['metadata']['name'] AS node\nORDER BY pod, node", "tokens": {"prompt": 17348, "output": 94, "total": 17442}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nMATCH (p)-[:RunsOn]->(n:Node)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod,\n       n['metadata']['name'] AS node\nORDER BY pod, node", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2195, "total_tokens": 17442, "total_prompt_tokens": 17348, "total_output_tokens": 94}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m12", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nOPTIONAL MATCH (p)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)\nRETURN\n  p.metadata.name AS pod,\n  collect(DISTINCT pvc.metadata.name) AS pvcs\nORDER BY pod;", "tokens": {"prompt": 17348, "output": 120, "total": 17468}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nOPTIONAL MATCH (p)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)\nRETURN\n  p.metadata.name AS pod,\n  collect(DISTINCT pvc.metadata.name) AS pvcs\nORDER BY pod;", "rows": 7}, "metrics": {"attempts": 1, "latency_ms": 3291, "total_tokens": 17468, "total_prompt_tokens": 17348, "total_output_tokens": 120}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m13", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (c)-[:Runs]->(p:Pod)\nRETURN\n  ns['metadata']['name'] AS namespace,\n  p['metadata']['name'] AS pod,\n  c['spec']['name'] AS container,\n  c['container_type'] AS container_type\nORDER BY pod, container;", "tokens": {"prompt": 17348, "output": 118, "total": 17466}}], "final": {"valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (c)-[:Runs]->(p:Pod)\nRETURN\n  ns['metadata']['name'] AS namespace,\n  p['metadata']['name'] AS pod,\n  c['spec']['name'] AS container,\n  c['container_type'] AS container_type\nORDER BY pod, container;", "rows": 9}, "metrics": {"attempts": 1, "latency_ms": 2601, "total_tokens": 17466, "total_prompt_tokens": 17348, "total_output_tokens": 118}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m14", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (c:Container)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (c)-[:HasLogs]->(l:Logs)\nRETURN \n  ns['metadata']['name'] AS namespace,\n  c['metadata']['name'] AS container_name,\n  c['pod_name'] AS pod_name,\n  c['pod_uid'] AS pod_uid,\n  c['container_type'] AS container_type,\n  l['content'] AS logs\nORDER BY pod_name, container_name\nLIMIT 1000", "tokens": {"prompt": 17348, "output": 186, "total": 17534}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (c:Container)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (c)-[:HasLogs]->(l:Logs)\nRETURN \n  ns['metadata']['name'] AS namespace,\n  c['metadata']['name'] AS container_name,\n  c['pod_name'] AS pod_name,\n  c['pod_uid'] AS pod_uid,\n  c['container_type'] AS container_type,\n  l['content'] AS logs\nORDER BY pod_name, container_name\nLIMIT 1000", "rows": 9}, "metrics": {"attempts": 1, "latency_ms": 3681, "total_tokens": 17534, "total_prompt_tokens": 17348, "total_output_tokens": 186}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m15", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ing:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(svc:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ing['metadata']['name'] AS ingress,\n  b['name'] AS backend_name,\n  b['port'] AS backend_port,\n  svc['metadata']['name'] AS service,\n  svc['spec']['type'] AS service_type\nORDER BY ingress, service;", "tokens": {"prompt": 17348, "output": 177, "total": 17525}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ing:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(svc:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ing['metadata']['name'] AS ingress,\n  b['name'] AS backend_name,\n  b['port'] AS backend_port,\n  svc['metadata']['name'] AS service,\n  svc['spec']['type'] AS service_type\nORDER BY ingress, service;", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 4419, "total_tokens": 17525, "total_prompt_tokens": 17348, "total_output_tokens": 177}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m16", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (es:EndpointSlice)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (es)-[:ContainsEndpoint]->(ep:Endpoint)\nOPTIONAL MATCH (ep)-[:HasAddress]->(ea:EndpointAddress)\nOPTIONAL MATCH (ea)-[:IsAddressOf]->(p:Pod)\nRETURN\n  es['metadata']['name'] AS endpoint_slice,\n  collect(DISTINCT {\n    pod_name: p['metadata']['name'],\n    pod_namespace: p['metadata']['namespace'],\n    pod_uid: p['metadata']['uid'],\n    endpoint_address: ea.address\n  }) AS referenced_pods\nORDER BY endpoint_slice;", "tokens": {"prompt": 17348, "output": 224, "total": 17572}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (es:EndpointSlice)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (es)-[:ContainsEndpoint]->(ep:Endpoint)\nOPTIONAL MATCH (ep)-[:HasAddress]->(ea:EndpointAddress)\nOPTIONAL MATCH (ea)-[:IsAddressOf]->(p:Pod)\nRETURN\n  es['metadata']['name'] AS endpoint_slice,\n  collect(DISTINCT {\n    pod_name: p['metadata']['name'],\n    pod_namespace: p['metadata']['namespace'],\n    pod_uid: p['metadata']['uid'],\n    endpoint_address: ea.address\n  }) AS referenced_pods\nORDER BY endpoint_slice;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 5713, "total_tokens": 17572, "total_prompt_tokens": 17348, "total_output_tokens": 224}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m17", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(s:Service)\nMATCH (s)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  e['metadata']['name'] AS event_name,\n  e['type'] AS type,\n  e['reason'] AS reason,\n  e['note'] AS note,\n  e['action'] AS action,\n  e['eventTime'] AS event_time,\n  e['deprecatedFirstTimestamp'] AS first_timestamp,\n  e['deprecatedLastTimestamp'] AS last_timestamp,\n  s['metadata']['name'] AS service_name,\n  ns['metadata']['name'] AS namespace\nORDER BY coalesce(e['eventTime'], e['deprecatedLastTimestamp'], e['deprecatedFirstTimestamp']) DESC;", "tokens": {"prompt": 17344, "output": 250, "total": 17594}}], "final": {"valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(s:Service)\nMATCH (s)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  e['metadata']['name'] AS event_name,\n  e['type'] AS type,\n  e['reason'] AS reason,\n  e['note'] AS note,\n  e['action'] AS action,\n  e['eventTime'] AS event_time,\n  e['deprecatedFirstTimestamp'] AS first_timestamp,\n  e['deprecatedLastTimestamp'] AS last_timestamp,\n  s['metadata']['name'] AS service_name,\n  ns['metadata']['name'] AS namespace\nORDER BY coalesce(e['eventTime'], e['deprecatedLastTimestamp'], e['deprecatedFirstTimestamp']) DESC;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 7940, "total_tokens": 17594, "total_prompt_tokens": 17344, "total_output_tokens": 250}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m18", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pv['metadata']['name'] AS persistent_volume,\n  pv['spec']['storageClassName'] AS pv_spec_storageClassName,\n  sc['metadata']['name'] AS storage_class\nORDER BY persistent_volume, storage_class;", "tokens": {"prompt": 17344, "output": 141, "total": 17485}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pv['metadata']['name'] AS persistent_volume,\n  pv['spec']['storageClassName'] AS pv_spec_storageClassName,\n  sc['metadata']['name'] AS storage_class\nORDER BY persistent_volume, storage_class;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5183, "total_tokens": 17485, "total_prompt_tokens": 17344, "total_output_tokens": 141}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m19", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nRETURN n['metadata']['name'] AS node_name, COUNT(p) AS pod_count\nORDER BY pod_count DESC, node_name ASC", "tokens": {"prompt": 17345, "output": 95, "total": 17440}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nRETURN n['metadata']['name'] AS node_name, COUNT(p) AS pod_count\nORDER BY pod_count DESC, node_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2380, "total_tokens": 17440, "total_prompt_tokens": 17345, "total_output_tokens": 95}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m20", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(s) AS service_count\nORDER BY service_count DESC, namespace ASC", "tokens": {"prompt": 17341, "output": 68, "total": 17409}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(s) AS service_count\nORDER BY service_count DESC, namespace ASC", "rows": 20}, "metrics": {"attempts": 1, "latency_ms": 1898, "total_tokens": 17409, "total_prompt_tokens": 17341, "total_output_tokens": 68}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h01", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(p) AS pod_count\nORDER BY pod_count DESC\nLIMIT 5", "tokens": {"prompt": 17351, "output": 69, "total": 17420}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(p) AS pod_count\nORDER BY pod_count DESC\nLIMIT 5", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 1823, "total_tokens": 17420, "total_prompt_tokens": 17351, "total_output_tokens": 69}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h02", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, COUNT(p) AS pod_count\nWHERE pod_count > 50\nRETURN n['metadata']['name'] AS node_name, pod_count\nORDER BY pod_count DESC, node_name ASC", "tokens": {"prompt": 17343, "output": 127, "total": 17470}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, COUNT(p) AS pod_count\nWHERE pod_count > 50\nRETURN n['metadata']['name'] AS node_name, pod_count\nORDER BY pod_count DESC, node_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3101, "total_tokens": 17470, "total_prompt_tokens": 17343, "total_output_tokens": 127}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h03", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nUNWIND p['spec']['containers'] AS container\nWITH ns, container['resources']['requests'] AS reqs, container['resources']['limits'] AS lims\nWITH ns,\n  CASE\n    WHEN reqs['memory'] IS NULL THEN 0.0\n    WHEN reqs['memory'] ENDS WITH 'Ti' THEN toFloat(replace(reqs['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN reqs['memory'] ENDS WITH 'Gi' THEN toFloat(replace(reqs['memory'], 'Gi', '')) * 1024\n    WHEN reqs['memory'] ENDS WITH 'Mi' THEN toFloat(replace(reqs['memory'], 'Mi', ''))\n    WHEN reqs['memory'] ENDS WITH 'Ki' THEN toFloat(replace(reqs['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(reqs['memory'])\n  END AS req_memory_mib,\n  CASE\n    WHEN lims['memory'] IS NULL THEN 0.0\n    WHEN lims['memory'] ENDS WITH 'Ti' THEN toFloat(replace(lims['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN lims['memory'] ENDS WITH 'Gi' THEN toFloat(replace(lims['memory'], 'Gi', '')) * 1024\n    WHEN lims['memory'] ENDS WITH 'Mi' THEN toFloat(replace(lims['memory'], 'Mi', ''))\n    WHEN lims['memory'] ENDS WITH 'Ki' THEN toFloat(replace(lims['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(lims['memory'])\n  END AS lim_memory_mib\nRETURN ns['metadata']['name'] AS namespace,\n  SUM(req_memory_mib) AS total_requested_memory_mib,\n  SUM(lim_memory_mib) AS total_limit_memory_mib\nORDER BY total_requested_memory_mib DESC;", "tokens": {"prompt": 17353, "output": 540, "total": 17893}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nUNWIND p['spec']['containers'] AS container\nWITH ns, container['resources']['requests'] AS reqs, container['resources']['limits'] AS lims\nWITH ns,\n  CASE\n    WHEN reqs['memory'] IS NULL THEN 0.0\n    WHEN reqs['memory'] ENDS WITH 'Ti' THEN toFloat(replace(reqs['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN reqs['memory'] ENDS WITH 'Gi' THEN toFloat(replace(reqs['memory'], 'Gi', '')) * 1024\n    WHEN reqs['memory'] ENDS WITH 'Mi' THEN toFloat(replace(reqs['memory'], 'Mi', ''))\n    WHEN reqs['memory'] ENDS WITH 'Ki' THEN toFloat(replace(reqs['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(reqs['memory'])\n  END AS req_memory_mib,\n  CASE\n    WHEN lims['memory'] IS NULL THEN 0.0\n    WHEN lims['memory'] ENDS WITH 'Ti' THEN toFloat(replace(lims['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN lims['memory'] ENDS WITH 'Gi' THEN toFloat(replace(lims['memory'], 'Gi', '')) * 1024\n    WHEN lims['memory'] ENDS WITH 'Mi' THEN toFloat(replace(lims['memory'], 'Mi', ''))\n    WHEN lims['memory'] ENDS WITH 'Ki' THEN toFloat(replace(lims['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(lims['memory'])\n  END AS lim_memory_mib\nRETURN ns['metadata']['name'] AS namespace,\n  SUM(req_memory_mib) AS total_requested_memory_mib,\n  SUM(lim_memory_mib) AS total_limit_memory_mib\nORDER BY total_requested_memory_mib DESC;", "rows": 24}, "metrics": {"attempts": 1, "latency_ms": 10001, "total_tokens": 17893, "total_prompt_tokens": 17353, "total_output_tokens": 540}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h04", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'default'\n  AND NOT EXISTS { MATCH (s)-[:Manages]->(:EndpointSlice) }\nRETURN s['metadata']['name'] AS service_name,\n       s['spec']['type'] AS service_type,\n       s['spec']['clusterIP'] AS cluster_ip\nORDER BY service_name", "tokens": {"prompt": 17345, "output": 158, "total": 17503}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'default'\n  AND NOT EXISTS { MATCH (s)-[:Manages]->(:EndpointSlice) }\nRETURN s['metadata']['name'] AS service_name,\n       s['spec']['type'] AS service_type,\n       s['spec']['clusterIP'] AS cluster_ip\nORDER BY service_name", "rows": 4}, "metrics": {"attempts": 1, "latency_ms": 3475, "total_tokens": 17503, "total_prompt_tokens": 17345, "total_output_tokens": 158}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h05", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ing:Ingress)-[:DefinesBackend]->(be:IngressServiceBackend)-[:TargetsService]->(svc:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN DISTINCT\n  ing['metadata']['name'] AS ingress,\n  svc['metadata']['name'] AS service,\n  es['metadata']['name'] AS endpointSlice\nORDER BY ingress, service, endpointSlice", "tokens": {"prompt": 17347, "output": 207, "total": 17554}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ing:Ingress)-[:DefinesBackend]->(be:IngressServiceBackend)-[:TargetsService]->(svc:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN DISTINCT\n  ing['metadata']['name'] AS ingress,\n  svc['metadata']['name'] AS service,\n  es['metadata']['name'] AS endpointSlice\nORDER BY ingress, service, endpointSlice", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 7181, "total_tokens": 17554, "total_prompt_tokens": 17347, "total_output_tokens": 207}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h06", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": false, "error": "Cypher schema validation failed:\n- Invalid relationship: Endpoint <- EndpointAddress via ListedIn. Allowed: EndpointAddress -> EndpointSlice. Pattern: (:Endpoint)<-[:ListedIn]-(ea:EndpointAddress) [rule=script/query/regularQuery/singleQuery/singlePartQ/readingStatement/matchSt/patternWhere/pattern/patternPart/patternElem/patternElemChain/relationshipPattern]\n  Hint: ListedIn is only allowed as EndpointAddress -> EndpointSlice. Check direction and node labels.", "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(ing:Ingress)-[:DefinesBackend]->(be:IngressServiceBackend)-[:TargetsService]->(svc:Service)\nWHERE h.name = 'litmus.qa.agoda.is'\nOPTIONAL MATCH (svc)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(:Endpoint)<-[:ListedIn]-(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN\n  h.name AS host,\n  ing.metadata.name AS ingress_name,\n  ing.metadata.namespace AS ingress_namespace,\n  svc.metadata.name AS service_name,\n  svc.metadata.namespace AS service_namespace,\n  collect(DISTINCT p.metadata.name) AS backing_pods\nORDER BY ingress_namespace, ingress_name, service_namespace, service_name", "tokens": {"prompt": 17352, "output": 277, "total": 17629}}, {"attempt": 2, "valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(ing:Ingress)-[:DefinesBackend]->(be:IngressServiceBackend)-[:TargetsService]->(svc:Service)\nWHERE h.name = 'litmus.qa.agoda.is'\nOPTIONAL MATCH (svc)-[:Manages]->(es:EndpointSlice)\nOPTIONAL MATCH (es)<-[:ListedIn]-(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN\n  h.name AS host,\n  ing.metadata.name AS ingress_name,\n  ing.metadata.namespace AS ingress_namespace,\n  svc.metadata.name AS service_name,\n  svc.metadata.namespace AS service_namespace,\n  collect(DISTINCT p.metadata.name) AS backing_pods\nORDER BY ingress_namespace, ingress_name, service_namespace, service_name", "tokens": {"prompt": 17655, "output": 261, "total": 17916}}], "final": {"valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(ing:Ingress)-[:DefinesBackend]->(be:IngressServiceBackend)-[:TargetsService]->(svc:Service)\nWHERE h.name = 'litmus.qa.agoda.is'\nOPTIONAL MATCH (svc)-[:Manages]->(es:EndpointSlice)\nOPTIONAL MATCH (es)<-[:ListedIn]-(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN\n  h.name AS host,\n  ing.metadata.name AS ingress_name,\n  ing.metadata.namespace AS ingress_namespace,\n  svc.metadata.name AS service_name,\n  svc.metadata.namespace AS service_namespace,\n  collect(DISTINCT p.metadata.name) AS backing_pods\nORDER BY ingress_namespace, ingress_name, service_namespace, service_name", "rows": 2}, "metrics": {"attempts": 2, "latency_ms": 11333, "total_tokens": 35545, "total_prompt_tokens": 35007, "total_output_tokens": 538}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h07", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:Endpoint)\nUNWIND e['addresses'] AS addr\nWITH s, addr\nMATCH (p:Pod)\nWHERE p['status']['podIP'] = addr\nWITH s, COLLECT(DISTINCT addr) AS backing_pod_ips\nRETURN s['metadata']['namespace'] AS namespace,\n       s['metadata']['name'] AS service,\n       SIZE(backing_pod_ips) AS distinct_backing_pod_ip_count,\n       backing_pod_ips\nORDER BY distinct_backing_pod_ip_count DESC, namespace, service", "tokens": {"prompt": 17345, "output": 214, "total": 17559}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:Endpoint)\nUNWIND e['addresses'] AS addr\nWITH s, addr\nMATCH (p:Pod)\nWHERE p['status']['podIP'] = addr\nWITH s, COLLECT(DISTINCT addr) AS backing_pod_ips\nRETURN s['metadata']['namespace'] AS namespace,\n       s['metadata']['name'] AS service,\n       SIZE(backing_pod_ips) AS distinct_backing_pod_ip_count,\n       backing_pod_ips\nORDER BY distinct_backing_pod_ip_count DESC, namespace, service", "rows": 102}, "metrics": {"attempts": 1, "latency_ms": 5239, "total_tokens": 17559, "total_prompt_tokens": 17345, "total_output_tokens": 214}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h08", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:Deployment)\nWITH d,\n  coalesce(d['spec']['replicas'], 1) AS desired,\n  coalesce(d['status']['readyReplicas'], 0) AS ready\nWHERE ready < desired\nRETURN\n  d['metadata']['namespace'] AS namespace,\n  d['metadata']['name'] AS deployment,\n  desired AS desired_replicas,\n  ready AS ready_replicas,\n  (desired - ready) AS missing_ready_replicas\nORDER BY missing_ready_replicas DESC, namespace ASC, deployment ASC", "tokens": {"prompt": 17345, "output": 168, "total": 17513}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:Deployment)\nWITH d,\n  coalesce(d['spec']['replicas'], 1) AS desired,\n  coalesce(d['status']['readyReplicas'], 0) AS ready\nWHERE ready < desired\nRETURN\n  d['metadata']['namespace'] AS namespace,\n  d['metadata']['name'] AS deployment,\n  desired AS desired_replicas,\n  ready AS ready_replicas,\n  (desired - ready) AS missing_ready_replicas\nORDER BY missing_ready_replicas DESC, namespace ASC, deployment ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4156, "total_tokens": 17513, "total_prompt_tokens": 17345, "total_output_tokens": 168}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h09", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'storefront'\n  AND NOT EXISTS { MATCH (d:Deployment)-[:Manages]->(:ReplicaSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (ss:StatefulSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (ds:DaemonSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (j:Job)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (rs:ReplicaSet)-[:Manages]->(p) }\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['metadata']['uid'] AS pod_uid,\n       p['status']['phase'] AS phase\nORDER BY pod_name;", "tokens": {"prompt": 17360, "output": 264, "total": 17624}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'storefront'\n  AND NOT EXISTS { MATCH (d:Deployment)-[:Manages]->(:ReplicaSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (ss:StatefulSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (ds:DaemonSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (j:Job)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (rs:ReplicaSet)-[:Manages]->(p) }\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['metadata']['uid'] AS pod_uid,\n       p['status']['phase'] AS phase\nORDER BY pod_name;", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 6999, "total_tokens": 17624, "total_prompt_tokens": 17360, "total_output_tokens": 264}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h10", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'pyroscope'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nOPTIONAL MATCH (pv)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN \n  pvc['metadata']['name'] AS pvc_name,\n  pvc['status']['phase'] AS pvc_phase,\n  pv['metadata']['name'] AS bound_pv_name,\n  sc['metadata']['name'] AS storage_class\nORDER BY pvc_name;", "tokens": {"prompt": 17353, "output": 191, "total": 17544}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'pyroscope'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nOPTIONAL MATCH (pv)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN \n  pvc['metadata']['name'] AS pvc_name,\n  pvc['status']['phase'] AS pvc_phase,\n  pv['metadata']['name'] AS bound_pv_name,\n  sc['metadata']['name'] AS storage_class\nORDER BY pvc_name;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 5209, "total_tokens": 17544, "total_prompt_tokens": 17353, "total_output_tokens": 191}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h11", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND NOT EXISTS { MATCH (s)-[:Manages]->(:EndpointSlice) }\nRETURN s['metadata']['name'] AS service_name,\n       s['spec']['type'] AS service_type,\n       s['spec']['clusterIP'] AS cluster_ip\nORDER BY service_name", "tokens": {"prompt": 17346, "output": 159, "total": 17505}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND NOT EXISTS { MATCH (s)-[:Manages]->(:EndpointSlice) }\nRETURN s['metadata']['name'] AS service_name,\n       s['spec']['type'] AS service_type,\n       s['spec']['clusterIP'] AS cluster_ip\nORDER BY service_name", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5014, "total_tokens": 17505, "total_prompt_tokens": 17346, "total_output_tokens": 159}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h12", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (i)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH i, s, COUNT(es) AS endpoint_slices\nWHERE endpoint_slices = 0\nRETURN i['metadata']['name'] AS ingress,\n       s['metadata']['name'] AS backend_service\nORDER BY ingress, backend_service", "tokens": {"prompt": 17351, "output": 189, "total": 17540}}], "final": {"valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (i)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH i, s, COUNT(es) AS endpoint_slices\nWHERE endpoint_slices = 0\nRETURN i['metadata']['name'] AS ingress,\n       s['metadata']['name'] AS backend_service\nORDER BY ingress, backend_service", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4729, "total_tokens": 17540, "total_prompt_tokens": 17351, "total_output_tokens": 189}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h13", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND NOT EXISTS { MATCH (pvc)-[:BoundTo]->(:PersistentVolume) }\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['metadata']['namespace'] AS namespace,\n       pvc['status']['phase'] AS phase,\n       pvc['spec']['volumeName'] AS spec_volumeName\nORDER BY pvc_name;", "tokens": {"prompt": 17349, "output": 167, "total": 17516}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND NOT EXISTS { MATCH (pvc)-[:BoundTo]->(:PersistentVolume) }\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['metadata']['namespace'] AS namespace,\n       pvc['status']['phase'] AS phase,\n       pvc['spec']['volumeName'] AS spec_volumeName\nORDER BY pvc_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5207, "total_tokens": 17516, "total_prompt_tokens": 17349, "total_output_tokens": 167}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h14", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)-[:BoundTo]->(pv:PersistentVolume)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND (pv['spec']['storageClassName'] IS NULL OR pv['spec']['storageClassName'] = '')\nRETURN\n  p['metadata']['name'] AS pod,\n  pvc['metadata']['name'] AS pvc,\n  pv['metadata']['name'] AS pv,\n  pv['spec']['storageClassName'] AS pv_storage_class\nORDER BY pod, pvc, pv;", "tokens": {"prompt": 17351, "output": 200, "total": 17551}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)-[:BoundTo]->(pv:PersistentVolume)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND (pv['spec']['storageClassName'] IS NULL OR pv['spec']['storageClassName'] = '')\nRETURN\n  p['metadata']['name'] AS pod,\n  pvc['metadata']['name'] AS pvc,\n  pv['metadata']['name'] AS pv,\n  pv['spec']['storageClassName'] AS pv_storage_class\nORDER BY pod, pvc, pv;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 7327, "total_tokens": 17551, "total_prompt_tokens": 17351, "total_output_tokens": 200}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h15", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, COUNT(DISTINCT p['metadata']['namespace']) AS distinct_pod_namespaces\nWHERE distinct_pod_namespaces > 1\nRETURN\n  n['metadata']['name'] AS node_name,\n  distinct_pod_namespaces\nORDER BY distinct_pod_namespaces DESC, node_name ASC", "tokens": {"prompt": 17355, "output": 146, "total": 17501}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, COUNT(DISTINCT p['metadata']['namespace']) AS distinct_pod_namespaces\nWHERE distinct_pod_namespaces > 1\nRETURN\n  n['metadata']['name'] AS node_name,\n  distinct_pod_namespaces\nORDER BY distinct_pod_namespaces DESC, node_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4733, "total_tokens": 17501, "total_prompt_tokens": 17355, "total_output_tokens": 146}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h16", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (d)-[:Manages]->(rs:ReplicaSet)-[:Manages]->(p:Pod)\nRETURN d['metadata']['name'] AS deployment,\n       COUNT(DISTINCT p) AS managed_pod_count\nORDER BY managed_pod_count DESC, deployment ASC;", "tokens": {"prompt": 17351, "output": 160, "total": 17511}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (d)-[:Manages]->(rs:ReplicaSet)-[:Manages]->(p:Pod)\nRETURN d['metadata']['name'] AS deployment,\n       COUNT(DISTINCT p) AS managed_pod_count\nORDER BY managed_pod_count DESC, deployment ASC;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 4838, "total_tokens": 17511, "total_prompt_tokens": 17351, "total_output_tokens": 160}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h17", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND EXISTS {\n    MATCH (e:Event)-[:Concerns]->(p)\n    WHERE e['type'] = 'Warning'\n  }\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['status']['phase'] AS phase\nORDER BY pod_name;", "tokens": {"prompt": 17348, "output": 160, "total": 17508}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND EXISTS {\n    MATCH (e:Event)-[:Concerns]->(p)\n    WHERE e['type'] = 'Warning'\n  }\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['status']['phase'] AS phase\nORDER BY pod_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 6394, "total_tokens": 17508, "total_prompt_tokens": 17348, "total_output_tokens": 160}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h18", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nOPTIONAL MATCH (ns)<-[:BelongsTo]-(s:Service)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH ns, s, COUNT(es) AS endpointSliceCount\nWITH ns, SUM(CASE WHEN s IS NOT NULL AND endpointSliceCount = 0 THEN 1 ELSE 0 END) AS servicesWithZeroEndpointSlices\nRETURN ns['metadata']['name'] AS namespace, servicesWithZeroEndpointSlices\nORDER BY servicesWithZeroEndpointSlices DESC, namespace ASC", "tokens": {"prompt": 17345, "output": 173, "total": 17518}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nOPTIONAL MATCH (ns)<-[:BelongsTo]-(s:Service)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH ns, s, COUNT(es) AS endpointSliceCount\nWITH ns, SUM(CASE WHEN s IS NOT NULL AND endpointSliceCount = 0 THEN 1 ELSE 0 END) AS servicesWithZeroEndpointSlices\nRETURN ns['metadata']['name'] AS namespace, servicesWithZeroEndpointSlices\nORDER BY servicesWithZeroEndpointSlices DESC, namespace ASC", "rows": 34}, "metrics": {"attempts": 1, "latency_ms": 6136, "total_tokens": 17518, "total_prompt_tokens": 17345, "total_output_tokens": 173}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h19", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(i:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nRETURN\n  h.name AS host,\n  i.metadata.name AS ingress_name,\n  i.metadata.namespace AS ingress_namespace,\n  b.name AS backend_name,\n  b.port AS backend_port,\n  s.metadata.name AS service_name,\n  s.metadata.namespace AS service_namespace\nORDER BY host, ingress_namespace, ingress_name, service_namespace, service_name", "tokens": {"prompt": 17344, "output": 182, "total": 17526}}], "final": {"valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(i:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nRETURN\n  h.name AS host,\n  i.metadata.name AS ingress_name,\n  i.metadata.namespace AS ingress_namespace,\n  b.name AS backend_name,\n  b.port AS backend_port,\n  s.metadata.name AS service_name,\n  s.metadata.namespace AS service_namespace\nORDER BY host, ingress_namespace, ingress_name, service_namespace, service_name", "rows": 26}, "metrics": {"attempts": 1, "latency_ms": 5347, "total_tokens": 17526, "total_prompt_tokens": 17344, "total_output_tokens": 182}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h20", "run_index": 1, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(ep:Endpoint)\nWITH s, ep\nUNWIND coalesce(ep.addresses, []) AS addr\nWITH s, addr\nMATCH (ea:EndpointAddress)\nWHERE ea.address = addr\nMATCH (ea)-[:IsAddressOf]->(p:Pod)\nWITH s, p['status']['phase'] AS phase, count(DISTINCT p) AS pod_count\nRETURN s.metadata.name AS service,\n       phase,\n       pod_count\nORDER BY service, phase", "tokens": {"prompt": 17347, "output": 243, "total": 17590}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(ep:Endpoint)\nWITH s, ep\nUNWIND coalesce(ep.addresses, []) AS addr\nWITH s, addr\nMATCH (ea:EndpointAddress)\nWHERE ea.address = addr\nMATCH (ea)-[:IsAddressOf]->(p:Pod)\nWITH s, p['status']['phase'] AS phase, count(DISTINCT p) AS pod_count\nRETURN s.metadata.name AS service,\n       phase,\n       pod_count\nORDER BY service, phase", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 8185, "total_tokens": 17590, "total_prompt_tokens": 17347, "total_output_tokens": 243}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e01", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       ns['metadata']['name'] AS namespace\nORDER BY cluster, namespace", "tokens": {"prompt": 17341, "output": 62, "total": 17403}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       ns['metadata']['name'] AS namespace\nORDER BY cluster, namespace", "rows": 34}, "metrics": {"attempts": 1, "latency_ms": 3746, "total_tokens": 17403, "total_prompt_tokens": 17341, "total_output_tokens": 62}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e02", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       count(ns) AS namespace_count\nORDER BY namespace_count DESC;", "tokens": {"prompt": 17343, "output": 101, "total": 17444}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       count(ns) AS namespace_count\nORDER BY namespace_count DESC;", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 3538, "total_tokens": 17444, "total_prompt_tokens": 17343, "total_output_tokens": 101}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e03", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['status']['phase'] AS phase,\n       p['metadata']['uid'] AS pod_uid\nORDER BY pod_name;", "tokens": {"prompt": 17342, "output": 104, "total": 17446}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['status']['phase'] AS phase,\n       p['metadata']['uid'] AS pod_uid\nORDER BY pod_name;", "rows": 7}, "metrics": {"attempts": 1, "latency_ms": 2625, "total_tokens": 17446, "total_prompt_tokens": 17342, "total_output_tokens": 104}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e04", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN s['metadata']['name'] AS service_name,\n       s['metadata']['namespace'] AS namespace,\n       s['spec']['type'] AS type,\n       s['spec']['clusterIP'] AS cluster_ip\nORDER BY service_name;", "tokens": {"prompt": 17342, "output": 105, "total": 17447}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN s['metadata']['name'] AS service_name,\n       s['metadata']['namespace'] AS namespace,\n       s['spec']['type'] AS type,\n       s['spec']['clusterIP'] AS cluster_ip\nORDER BY service_name;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 6922, "total_tokens": 17447, "total_prompt_tokens": 17342, "total_output_tokens": 105}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e05", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN i['metadata']['name'] AS ingress_name,\n       i['metadata']['namespace'] AS namespace,\n       i['spec']['ingressClassName'] AS ingress_class,\n       i['status']['loadBalancer'] AS load_balancer_status\nORDER BY ingress_name;", "tokens": {"prompt": 17343, "output": 146, "total": 17489}}], "final": {"valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN i['metadata']['name'] AS ingress_name,\n       i['metadata']['namespace'] AS namespace,\n       i['spec']['ingressClassName'] AS ingress_class,\n       i['status']['loadBalancer'] AS load_balancer_status\nORDER BY ingress_name;", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 3503, "total_tokens": 17489, "total_prompt_tokens": 17343, "total_output_tokens": 146}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e06", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (es:EndpointSlice)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN es['metadata']['name'] AS endpointSlice,\n       es['metadata']['namespace'] AS namespace,\n       es['addressType'] AS addressType,\n       es['metadata']['uid'] AS uid\nORDER BY endpointSlice;", "tokens": {"prompt": 17343, "output": 140, "total": 17483}}], "final": {"valid": true, "error": null, "cypher": "MATCH (es:EndpointSlice)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN es['metadata']['name'] AS endpointSlice,\n       es['metadata']['namespace'] AS namespace,\n       es['addressType'] AS addressType,\n       es['metadata']['uid'] AS uid\nORDER BY endpointSlice;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 3699, "total_tokens": 17483, "total_prompt_tokens": 17343, "total_output_tokens": 140}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e07", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       n.metadata.name AS node_name,\n       n.status.nodeInfo.kubeletVersion AS kubelet_version,\n       n.status.nodeInfo.containerRuntimeVersion AS container_runtime,\n       n.status.nodeInfo.osImage AS os_image\nORDER BY cluster, node_name;", "tokens": {"prompt": 17341, "output": 136, "total": 17477}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       n.metadata.name AS node_name,\n       n.status.nodeInfo.kubeletVersion AS kubelet_version,\n       n.status.nodeInfo.containerRuntimeVersion AS container_runtime,\n       n.status.nodeInfo.osImage AS os_image\nORDER BY cluster, node_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4992, "total_tokens": 17477, "total_prompt_tokens": 17341, "total_output_tokens": 136}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e08", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (sc:StorageClass)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       sc['metadata']['name'] AS storageClass,\n       sc['provisioner'] AS provisioner,\n       sc['reclaimPolicy'] AS reclaimPolicy,\n       sc['volumeBindingMode'] AS volumeBindingMode,\n       sc['allowVolumeExpansion'] AS allowVolumeExpansion\nORDER BY cluster, storageClass", "tokens": {"prompt": 17342, "output": 115, "total": 17457}}], "final": {"valid": true, "error": null, "cypher": "MATCH (sc:StorageClass)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       sc['metadata']['name'] AS storageClass,\n       sc['provisioner'] AS provisioner,\n       sc['reclaimPolicy'] AS reclaimPolicy,\n       sc['volumeBindingMode'] AS volumeBindingMode,\n       sc['allowVolumeExpansion'] AS allowVolumeExpansion\nORDER BY cluster, storageClass", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3060, "total_tokens": 17457, "total_prompt_tokens": 17342, "total_output_tokens": 115}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e09", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:PartOf]->(c:Cluster)\nRETURN\n  c.name AS cluster,\n  pv['metadata']['name'] AS persistent_volume,\n  pv['status']['phase'] AS phase,\n  pv['spec']['storageClassName'] AS storage_class,\n  pv['spec']['capacity'] AS capacity\nORDER BY persistent_volume;", "tokens": {"prompt": 17342, "output": 139, "total": 17481}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:PartOf]->(c:Cluster)\nRETURN\n  c.name AS cluster,\n  pv['metadata']['name'] AS persistent_volume,\n  pv['status']['phase'] AS phase,\n  pv['spec']['storageClassName'] AS storage_class,\n  pv['spec']['capacity'] AS capacity\nORDER BY persistent_volume;", "rows": 17}, "metrics": {"attempts": 1, "latency_ms": 2975, "total_tokens": 17481, "total_prompt_tokens": 17342, "total_output_tokens": 139}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e10", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (sa:ServiceAccount)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN sa['metadata']['name'] AS service_account,\n       sa['metadata']['namespace'] AS namespace\nORDER BY service_account;", "tokens": {"prompt": 17343, "output": 82, "total": 17425}}], "final": {"valid": true, "error": null, "cypher": "MATCH (sa:ServiceAccount)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN sa['metadata']['name'] AS service_account,\n       sa['metadata']['namespace'] AS namespace\nORDER BY service_account;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 3571, "total_tokens": 17425, "total_prompt_tokens": 17343, "total_output_tokens": 82}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e11", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN d['metadata']['name'] AS deployment,\n       d['metadata']['namespace'] AS namespace\nORDER BY deployment;", "tokens": {"prompt": 17342, "output": 79, "total": 17421}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN d['metadata']['name'] AS deployment,\n       d['metadata']['namespace'] AS namespace\nORDER BY deployment;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 2761, "total_tokens": 17421, "total_prompt_tokens": 17342, "total_output_tokens": 79}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e12", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (rs:ReplicaSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN rs['metadata']['name'] AS replicaset,\n       rs['metadata']['namespace'] AS namespace,\n       rs['metadata']['uid'] AS uid\nORDER BY replicaset;", "tokens": {"prompt": 17343, "output": 135, "total": 17478}}], "final": {"valid": true, "error": null, "cypher": "MATCH (rs:ReplicaSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN rs['metadata']['name'] AS replicaset,\n       rs['metadata']['namespace'] AS namespace,\n       rs['metadata']['uid'] AS uid\nORDER BY replicaset;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 4614, "total_tokens": 17478, "total_prompt_tokens": 17343, "total_output_tokens": 135}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e13", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:StatefulSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  s['metadata']['name'] AS statefulset,\n  s['metadata']['namespace'] AS namespace,\n  s['metadata']['uid'] AS uid\nORDER BY statefulset;", "tokens": {"prompt": 17344, "output": 137, "total": 17481}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:StatefulSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  s['metadata']['name'] AS statefulset,\n  s['metadata']['namespace'] AS namespace,\n  s['metadata']['uid'] AS uid\nORDER BY statefulset;", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 4119, "total_tokens": 17481, "total_prompt_tokens": 17344, "total_output_tokens": 137}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e14", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ds:DaemonSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ds['metadata']['name'] AS daemonset,\n       ds['metadata']['namespace'] AS namespace,\n       ds['metadata']['uid'] AS uid\nORDER BY daemonset;", "tokens": {"prompt": 17343, "output": 93, "total": 17436}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ds:DaemonSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ds['metadata']['name'] AS daemonset,\n       ds['metadata']['namespace'] AS namespace,\n       ds['metadata']['uid'] AS uid\nORDER BY daemonset;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3805, "total_tokens": 17436, "total_prompt_tokens": 17343, "total_output_tokens": 93}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e15", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (j:Job)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN j['metadata']['name'] AS job_name,\n       j['metadata']['namespace'] AS namespace,\n       j['status']['active'] AS active,\n       j['status']['succeeded'] AS succeeded,\n       j['status']['failed'] AS failed,\n       j['status']['startTime'] AS start_time,\n       j['status']['completionTime'] AS completion_time\nORDER BY job_name;", "tokens": {"prompt": 17342, "output": 141, "total": 17483}}], "final": {"valid": true, "error": null, "cypher": "MATCH (j:Job)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN j['metadata']['name'] AS job_name,\n       j['metadata']['namespace'] AS namespace,\n       j['status']['active'] AS active,\n       j['status']['succeeded'] AS succeeded,\n       j['status']['failed'] AS failed,\n       j['status']['startTime'] AS start_time,\n       j['status']['completionTime'] AS completion_time\nORDER BY job_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5176, "total_tokens": 17483, "total_prompt_tokens": 17342, "total_output_tokens": 141}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e16", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['metadata']['namespace'] AS namespace,\n       pvc['status']['phase'] AS phase,\n       pvc['spec']['storageClassName'] AS storage_class,\n       pvc['spec']['volumeName'] AS bound_pv_name\nORDER BY pvc_name;", "tokens": {"prompt": 17344, "output": 165, "total": 17509}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['metadata']['namespace'] AS namespace,\n       pvc['status']['phase'] AS phase,\n       pvc['spec']['storageClassName'] AS storage_class,\n       pvc['spec']['volumeName'] AS bound_pv_name\nORDER BY pvc_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3471, "total_tokens": 17509, "total_prompt_tokens": 17344, "total_output_tokens": 165}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e17", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN COUNT(p) AS pod_count", "tokens": {"prompt": 17343, "output": 61, "total": 17404}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN COUNT(p) AS pod_count", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 2452, "total_tokens": 17404, "total_prompt_tokens": 17343, "total_output_tokens": 61}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e18", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (cm:ConfigMap)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN cm['metadata']['name'] AS configmap,\n       cm['metadata']['namespace'] AS namespace\nORDER BY configmap", "tokens": {"prompt": 17343, "output": 117, "total": 17460}}], "final": {"valid": true, "error": null, "cypher": "MATCH (cm:ConfigMap)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN cm['metadata']['name'] AS configmap,\n       cm['metadata']['namespace'] AS namespace\nORDER BY configmap", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 3619, "total_tokens": 17460, "total_prompt_tokens": 17343, "total_output_tokens": 117}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e19", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": false, "error": "Cypher schema validation failed:\n- Invalid relationship: NetworkPolicy -> Namespace via BelongsTo. Allowed: Deployment -> Namespace; PersistentVolumeClaim -> Namespace; ReplicaSet -> Namespace; Job -> Namespace; Container -> Namespace; DaemonSet -> Namespace; Logs -> Namespace; Service -> Namespace; EndpointSlice -> Namespace; Ingress -> Namespace; Pod -> Namespace; ConfigMap -> Namespace; ServiceAccount -> Namespace; StatefulSet -> Namespace. Pattern: (np:NetworkPolicy)-[:BelongsTo]->(ns:Namespace) [rule=script/query/regularQuery/singleQuery/singlePartQ/readingStatement/matchSt/patternWhere/pattern/patternPart/patternElem/patternElemChain/relationshipPattern]\n  Hint: BelongsTo is only allowed as Deployment -> Namespace; PersistentVolumeClaim -> Namespace; ReplicaSet -> Namespace; Job -> Namespace; Container -> Namespace; DaemonSet -> Namespace; Logs -> Namespace; Service -> Namespace; EndpointSlice -> Namespace; Ingress -> Namespace; Pod -> Namespace; ConfigMap -> Namespace; ServiceAccount -> Namespace; StatefulSet -> Namespace. Check direction and node labels.", "cypher": "MATCH (np:NetworkPolicy)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  np['metadata']['name'] AS network_policy,\n  np['metadata']['namespace'] AS namespace,\n  np['metadata']['uid'] AS uid\nORDER BY network_policy;", "tokens": {"prompt": 17343, "output": 95, "total": 17438}}, {"attempt": 2, "valid": true, "error": null, "cypher": "MATCH (np:NetworkPolicy)\nWHERE np['metadata']['namespace'] = 'litmus'\nRETURN\n  np['metadata']['name'] AS network_policy,\n  np['metadata']['namespace'] AS namespace,\n  np['metadata']['uid'] AS uid\nORDER BY network_policy;", "tokens": {"prompt": 17676, "output": 110, "total": 17786}}], "final": {"valid": true, "error": null, "cypher": "MATCH (np:NetworkPolicy)\nWHERE np['metadata']['namespace'] = 'litmus'\nRETURN\n  np['metadata']['name'] AS network_policy,\n  np['metadata']['namespace'] AS namespace,\n  np['metadata']['uid'] AS uid\nORDER BY network_policy;", "rows": 0}, "metrics": {"attempts": 2, "latency_ms": 6134, "total_tokens": 35224, "total_prompt_tokens": 35019, "total_output_tokens": 205}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e20", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN \n  ns['metadata']['name'] AS namespace,\n  c['metadata']['name'] AS container_name,\n  c['pod_name'] AS pod_name,\n  c['container_type'] AS container_type,\n  c['spec']['image'] AS image\nORDER BY pod_name, container_name", "tokens": {"prompt": 17342, "output": 176, "total": 17518}}], "final": {"valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN \n  ns['metadata']['name'] AS namespace,\n  c['metadata']['name'] AS container_name,\n  c['pod_name'] AS pod_name,\n  c['container_type'] AS container_type,\n  c['spec']['image'] AS image\nORDER BY pod_name, container_name", "rows": 9}, "metrics": {"attempts": 1, "latency_ms": 4184, "total_tokens": 17518, "total_prompt_tokens": 17342, "total_output_tokens": 176}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m01", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (d:Deployment)-[:BelongsTo]->(ns)\nMATCH (d)-[:Manages]->(rs:ReplicaSet)\nRETURN d['metadata']['name'] AS deployment,\n       rs['metadata']['name'] AS replica_set\nORDER BY deployment, replica_set", "tokens": {"prompt": 17348, "output": 102, "total": 17450}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (d:Deployment)-[:BelongsTo]->(ns)\nMATCH (d)-[:Manages]->(rs:ReplicaSet)\nRETURN d['metadata']['name'] AS deployment,\n       rs['metadata']['name'] AS replica_set\nORDER BY deployment, replica_set", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 3692, "total_tokens": 17450, "total_prompt_tokens": 17348, "total_output_tokens": 102}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m02", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(rs:ReplicaSet)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  rs['metadata']['name'] AS replicaset,\n  collect(p['metadata']['name']) AS pods\nORDER BY replicaset;", "tokens": {"prompt": 17348, "output": 140, "total": 17488}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(rs:ReplicaSet)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  rs['metadata']['name'] AS replicaset,\n  collect(p['metadata']['name']) AS pods\nORDER BY replicaset;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 3442, "total_tokens": 17488, "total_prompt_tokens": 17348, "total_output_tokens": 140}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m03", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ds:DaemonSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (ds)-[:Manages]->(p:Pod)\nRETURN\n  ds['metadata']['name'] AS daemonset,\n  p['metadata']['name'] AS pod,\n  p['status']['phase'] AS pod_phase\nORDER BY daemonset, pod;", "tokens": {"prompt": 17348, "output": 148, "total": 17496}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ds:DaemonSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (ds)-[:Manages]->(p:Pod)\nRETURN\n  ds['metadata']['name'] AS daemonset,\n  p['metadata']['name'] AS pod,\n  p['status']['phase'] AS pod_phase\nORDER BY daemonset, pod;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5822, "total_tokens": 17496, "total_prompt_tokens": 17348, "total_output_tokens": 148}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m04", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ss:StatefulSet)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (ss)-[:Manages]->(p:Pod)\nRETURN\n  ss['metadata']['name'] AS statefulset,\n  collect(DISTINCT p['metadata']['name']) AS pods\nORDER BY statefulset;", "tokens": {"prompt": 17349, "output": 143, "total": 17492}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ss:StatefulSet)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (ss)-[:Manages]->(p:Pod)\nRETURN\n  ss['metadata']['name'] AS statefulset,\n  collect(DISTINCT p['metadata']['name']) AS pods\nORDER BY statefulset;", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 4224, "total_tokens": 17492, "total_prompt_tokens": 17349, "total_output_tokens": 143}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m05", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(j:Job)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ns['metadata']['name'] AS namespace,\n       j['metadata']['name'] AS job,\n       collect(DISTINCT p['metadata']['name']) AS pods\nORDER BY job;", "tokens": {"prompt": 17347, "output": 144, "total": 17491}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(j:Job)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ns['metadata']['name'] AS namespace,\n       j['metadata']['name'] AS job,\n       collect(DISTINCT p['metadata']['name']) AS pods\nORDER BY job;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3608, "total_tokens": 17491, "total_prompt_tokens": 17347, "total_output_tokens": 144}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m06", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(s:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ns['metadata']['name'] AS namespace,\n  s['metadata']['name'] AS service,\n  es['metadata']['name'] AS endpointSlice\nORDER BY service, endpointSlice;", "tokens": {"prompt": 17348, "output": 131, "total": 17479}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(s:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ns['metadata']['name'] AS namespace,\n  s['metadata']['name'] AS service,\n  es['metadata']['name'] AS endpointSlice\nORDER BY service, endpointSlice;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 4964, "total_tokens": 17479, "total_prompt_tokens": 17348, "total_output_tokens": 131}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m07", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": false, "error": "Cypher schema validation failed:\n- Invalid relationship: Endpoint <- EndpointAddress via ListedIn. Allowed: EndpointAddress -> EndpointSlice. Pattern: (ep:Endpoint)<-[:ListedIn]-(ea:EndpointAddress) [rule=script/query/regularQuery/singleQuery/multiPartQ/readingStatement/matchSt/patternWhere/pattern/patternPart/patternElem/patternElemChain/relationshipPattern]\n  Hint: ListedIn is only allowed as EndpointAddress -> EndpointSlice. Check direction and node labels.", "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(s:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(ep:Endpoint)<-[:ListedIn]-(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nOPTIONAL MATCH (p)-[:BelongsTo]->(pns:Namespace)\nWHERE pns['metadata']['name'] = 'litmus'\nWITH s, collect(DISTINCT p['metadata']['name']) AS pod_names\nRETURN s['metadata']['name'] AS service,\n       pod_names AS backing_pods\nORDER BY service;", "tokens": {"prompt": 17348, "output": 214, "total": 17562}}, {"attempt": 2, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(s:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(ep:Endpoint)\nOPTIONAL MATCH (ea:EndpointAddress)-[:ListedIn]->(es)\nOPTIONAL MATCH (ea)-[:IsAddressOf]->(p:Pod)-[:BelongsTo]->(pns:Namespace)\nWHERE pns['metadata']['name'] = 'litmus'\nWITH s, collect(DISTINCT p['metadata']['name']) AS pod_names\nRETURN s['metadata']['name'] AS service,\n       pod_names AS backing_pods\nORDER BY service;", "tokens": {"prompt": 17636, "output": 233, "total": 17869}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(s:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(ep:Endpoint)\nOPTIONAL MATCH (ea:EndpointAddress)-[:ListedIn]->(es)\nOPTIONAL MATCH (ea)-[:IsAddressOf]->(p:Pod)-[:BelongsTo]->(pns:Namespace)\nWHERE pns['metadata']['name'] = 'litmus'\nWITH s, collect(DISTINCT p['metadata']['name']) AS pod_names\nRETURN s['metadata']['name'] AS service,\n       pod_names AS backing_pods\nORDER BY service;", "rows": 5}, "metrics": {"attempts": 2, "latency_ms": 9603, "total_tokens": 35431, "total_prompt_tokens": 34984, "total_output_tokens": 447}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m08", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWHERE n['metadata']['name'] = '<node>' OR n.name = '<node>'\nRETURN p['metadata']['namespace'] AS namespace,\n       p['metadata']['name'] AS pod,\n       p['status']['phase'] AS phase\nORDER BY namespace, pod", "tokens": {"prompt": 17344, "output": 140, "total": 17484}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWHERE n['metadata']['name'] = '<node>' OR n.name = '<node>'\nRETURN p['metadata']['namespace'] AS namespace,\n       p['metadata']['name'] AS pod,\n       p['status']['phase'] AS phase\nORDER BY namespace, pod", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4937, "total_tokens": 17484, "total_prompt_tokens": 17344, "total_output_tokens": 140}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m09", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nRETURN\n  pvc['metadata']['name'] AS pvc_name,\n  pvc['metadata']['namespace'] AS namespace,\n  pvc['status']['phase'] AS pvc_phase,\n  pv['metadata']['name'] AS pv_name,\n  pv['status']['phase'] AS pv_phase,\n  pv['spec']['storageClassName'] AS pv_storage_class\nORDER BY pvc_name, pv_name", "tokens": {"prompt": 17351, "output": 191, "total": 17542}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nRETURN\n  pvc['metadata']['name'] AS pvc_name,\n  pvc['metadata']['namespace'] AS namespace,\n  pvc['status']['phase'] AS pvc_phase,\n  pv['metadata']['name'] AS pv_name,\n  pv['status']['phase'] AS pv_phase,\n  pv['spec']['storageClassName'] AS pv_storage_class\nORDER BY pvc_name, pv_name", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4348, "total_tokens": 17542, "total_prompt_tokens": 17351, "total_output_tokens": 191}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m10", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN e.reason AS event_reason,\n       p['metadata']['name'] AS pod_name,\n       e.type AS event_type,\n       e.note AS event_note,\n       e.eventTime AS event_time,\n       e.deprecatedLastTimestamp AS deprecated_last_timestamp\nORDER BY event_time DESC, deprecated_last_timestamp DESC, pod_name ASC", "tokens": {"prompt": 17349, "output": 166, "total": 17515}}], "final": {"valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN e.reason AS event_reason,\n       p['metadata']['name'] AS pod_name,\n       e.type AS event_type,\n       e.note AS event_note,\n       e.eventTime AS event_time,\n       e.deprecatedLastTimestamp AS deprecated_last_timestamp\nORDER BY event_time DESC, deprecated_last_timestamp DESC, pod_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4083, "total_tokens": 17515, "total_prompt_tokens": 17349, "total_output_tokens": 166}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m11", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nMATCH (p)-[:RunsOn]->(n:Node)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod, n['metadata']['name'] AS node\nORDER BY pod, node", "tokens": {"prompt": 17348, "output": 92, "total": 17440}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nMATCH (p)-[:RunsOn]->(n:Node)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod, n['metadata']['name'] AS node\nORDER BY pod, node", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2460, "total_tokens": 17440, "total_prompt_tokens": 17348, "total_output_tokens": 92}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m12", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  p['metadata']['name'] AS pod,\n  pvc['metadata']['name'] AS pvc\nORDER BY pod, pvc", "tokens": {"prompt": 17348, "output": 95, "total": 17443}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  p['metadata']['name'] AS pod,\n  pvc['metadata']['name'] AS pvc\nORDER BY pod, pvc", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2169, "total_tokens": 17443, "total_prompt_tokens": 17348, "total_output_tokens": 95}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m13", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (c)-[:Runs]->(p:Pod)\nRETURN ns['metadata']['name'] AS namespace,\n       p['metadata']['name'] AS pod,\n       c['spec']['name'] AS container_name,\n       c['metadata']['uid'] AS container_uid\nORDER BY pod, container_name", "tokens": {"prompt": 17348, "output": 118, "total": 17466}}], "final": {"valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (c)-[:Runs]->(p:Pod)\nRETURN ns['metadata']['name'] AS namespace,\n       p['metadata']['name'] AS pod,\n       c['spec']['name'] AS container_name,\n       c['metadata']['uid'] AS container_uid\nORDER BY pod, container_name", "rows": 9}, "metrics": {"attempts": 1, "latency_ms": 2844, "total_tokens": 17466, "total_prompt_tokens": 17348, "total_output_tokens": 118}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m14", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(c:Container)\nOPTIONAL MATCH (c)-[:HasLogs]->(l:Logs)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ns['metadata']['name'] AS namespace,\n  c['pod_name'] AS pod_name,\n  c['spec']['name'] AS container_name,\n  c['metadata']['uid'] AS container_uid,\n  l['content'] AS logs\nORDER BY pod_name, container_name", "tokens": {"prompt": 17348, "output": 172, "total": 17520}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(c:Container)\nOPTIONAL MATCH (c)-[:HasLogs]->(l:Logs)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ns['metadata']['name'] AS namespace,\n  c['pod_name'] AS pod_name,\n  c['spec']['name'] AS container_name,\n  c['metadata']['uid'] AS container_uid,\n  l['content'] AS logs\nORDER BY pod_name, container_name", "rows": 1212}, "metrics": {"attempts": 1, "latency_ms": 5468, "total_tokens": 17520, "total_prompt_tokens": 17348, "total_output_tokens": 172}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m15", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (i)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nRETURN \n  ns['metadata']['name'] AS namespace,\n  i['metadata']['name'] AS ingress,\n  collect(DISTINCT s['metadata']['name']) AS target_services\nORDER BY ingress", "tokens": {"prompt": 17348, "output": 170, "total": 17518}}], "final": {"valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (i)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nRETURN \n  ns['metadata']['name'] AS namespace,\n  i['metadata']['name'] AS ingress,\n  collect(DISTINCT s['metadata']['name']) AS target_services\nORDER BY ingress", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 4013, "total_tokens": 17518, "total_prompt_tokens": 17348, "total_output_tokens": 170}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m16", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (es)<-[:ListedIn]-(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN es['metadata']['name'] AS endpointSlice,\n       collect(DISTINCT {\n         pod: p['metadata']['name'],\n         pod_namespace: p['metadata']['namespace'],\n         pod_uid: p['metadata']['uid'],\n         address: ea.address\n       }) AS referenced_pods\nORDER BY endpointSlice;", "tokens": {"prompt": 17348, "output": 209, "total": 17557}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (es)<-[:ListedIn]-(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN es['metadata']['name'] AS endpointSlice,\n       collect(DISTINCT {\n         pod: p['metadata']['name'],\n         pod_namespace: p['metadata']['namespace'],\n         pod_uid: p['metadata']['uid'],\n         address: ea.address\n       }) AS referenced_pods\nORDER BY endpointSlice;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 4787, "total_tokens": 17557, "total_prompt_tokens": 17348, "total_output_tokens": 209}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m17", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(s:Service)\nMATCH (s)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nRETURN \n  e.metadata.name AS event_name,\n  e.type AS event_type,\n  e.reason AS reason,\n  e.note AS note,\n  e.eventTime AS event_time,\n  e.deprecatedFirstTimestamp AS first_timestamp,\n  e.deprecatedLastTimestamp AS last_timestamp,\n  e.action AS action,\n  s.metadata.name AS service_name,\n  s.metadata.namespace AS service_namespace\nORDER BY coalesce(e.eventTime, e.deprecatedLastTimestamp, e.deprecatedFirstTimestamp) DESC", "tokens": {"prompt": 17344, "output": 226, "total": 17570}}], "final": {"valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(s:Service)\nMATCH (s)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nRETURN \n  e.metadata.name AS event_name,\n  e.type AS event_type,\n  e.reason AS reason,\n  e.note AS note,\n  e.eventTime AS event_time,\n  e.deprecatedFirstTimestamp AS first_timestamp,\n  e.deprecatedLastTimestamp AS last_timestamp,\n  e.action AS action,\n  s.metadata.name AS service_name,\n  s.metadata.namespace AS service_namespace\nORDER BY coalesce(e.eventTime, e.deprecatedLastTimestamp, e.deprecatedFirstTimestamp) DESC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 6924, "total_tokens": 17570, "total_prompt_tokens": 17344, "total_output_tokens": 226}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m18", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pv['metadata']['name'] AS persistent_volume,\n  pv['spec']['storageClassName'] AS pv_storageClassName_field,\n  sc['metadata']['name'] AS storage_class\nORDER BY persistent_volume, storage_class", "tokens": {"prompt": 17344, "output": 139, "total": 17483}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pv['metadata']['name'] AS persistent_volume,\n  pv['spec']['storageClassName'] AS pv_storageClassName_field,\n  sc['metadata']['name'] AS storage_class\nORDER BY persistent_volume, storage_class", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3721, "total_tokens": 17483, "total_prompt_tokens": 17344, "total_output_tokens": 139}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m19", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nRETURN n['metadata']['name'] AS node_name, COUNT(p) AS pod_count\nORDER BY pod_count DESC, node_name ASC;", "tokens": {"prompt": 17345, "output": 106, "total": 17451}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nRETURN n['metadata']['name'] AS node_name, COUNT(p) AS pod_count\nORDER BY pod_count DESC, node_name ASC;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3455, "total_tokens": 17451, "total_prompt_tokens": 17345, "total_output_tokens": 106}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m20", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(s) AS service_count\nORDER BY service_count DESC, namespace ASC", "tokens": {"prompt": 17341, "output": 68, "total": 17409}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(s) AS service_count\nORDER BY service_count DESC, namespace ASC", "rows": 20}, "metrics": {"attempts": 1, "latency_ms": 2250, "total_tokens": 17409, "total_prompt_tokens": 17341, "total_output_tokens": 68}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h01", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(p) AS pod_count\nORDER BY pod_count DESC\nLIMIT 5", "tokens": {"prompt": 17351, "output": 70, "total": 17421}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(p) AS pod_count\nORDER BY pod_count DESC\nLIMIT 5", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 2498, "total_tokens": 17421, "total_prompt_tokens": 17351, "total_output_tokens": 70}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h02", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, COUNT(p) AS pod_count\nWHERE pod_count > 50\nRETURN n['metadata']['name'] AS node_name, pod_count\nORDER BY pod_count DESC, node_name ASC", "tokens": {"prompt": 17343, "output": 81, "total": 17424}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, COUNT(p) AS pod_count\nWHERE pod_count > 50\nRETURN n['metadata']['name'] AS node_name, pod_count\nORDER BY pod_count DESC, node_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4716, "total_tokens": 17424, "total_prompt_tokens": 17343, "total_output_tokens": 81}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h03", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nUNWIND p['spec']['containers'] AS container\nWITH ns, container['resources']['requests'] AS reqs, container['resources']['limits'] AS lims\nWITH ns,\n  CASE\n    WHEN lims['memory'] IS NULL THEN 0.0\n    WHEN lims['memory'] ENDS WITH 'Ti' THEN toFloat(replace(lims['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN lims['memory'] ENDS WITH 'Gi' THEN toFloat(replace(lims['memory'], 'Gi', '')) * 1024\n    WHEN lims['memory'] ENDS WITH 'Mi' THEN toFloat(replace(lims['memory'], 'Mi', ''))\n    WHEN lims['memory'] ENDS WITH 'Ki' THEN toFloat(replace(lims['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(lims['memory'])\n  END AS lim_memory_mib,\n  CASE\n    WHEN reqs['memory'] IS NULL THEN 0.0\n    WHEN reqs['memory'] ENDS WITH 'Ti' THEN toFloat(replace(reqs['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN reqs['memory'] ENDS WITH 'Gi' THEN toFloat(replace(reqs['memory'], 'Gi', '')) * 1024\n    WHEN reqs['memory'] ENDS WITH 'Mi' THEN toFloat(replace(reqs['memory'], 'Mi', ''))\n    WHEN reqs['memory'] ENDS WITH 'Ki' THEN toFloat(replace(reqs['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(reqs['memory'])\n  END AS req_memory_mib\nRETURN ns['metadata']['name'] AS namespace,\n       SUM(req_memory_mib) AS total_requested_memory_mib,\n       SUM(lim_memory_mib) AS total_limit_memory_mib\nORDER BY total_requested_memory_mib DESC", "tokens": {"prompt": 17353, "output": 536, "total": 17889}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nUNWIND p['spec']['containers'] AS container\nWITH ns, container['resources']['requests'] AS reqs, container['resources']['limits'] AS lims\nWITH ns,\n  CASE\n    WHEN lims['memory'] IS NULL THEN 0.0\n    WHEN lims['memory'] ENDS WITH 'Ti' THEN toFloat(replace(lims['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN lims['memory'] ENDS WITH 'Gi' THEN toFloat(replace(lims['memory'], 'Gi', '')) * 1024\n    WHEN lims['memory'] ENDS WITH 'Mi' THEN toFloat(replace(lims['memory'], 'Mi', ''))\n    WHEN lims['memory'] ENDS WITH 'Ki' THEN toFloat(replace(lims['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(lims['memory'])\n  END AS lim_memory_mib,\n  CASE\n    WHEN reqs['memory'] IS NULL THEN 0.0\n    WHEN reqs['memory'] ENDS WITH 'Ti' THEN toFloat(replace(reqs['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN reqs['memory'] ENDS WITH 'Gi' THEN toFloat(replace(reqs['memory'], 'Gi', '')) * 1024\n    WHEN reqs['memory'] ENDS WITH 'Mi' THEN toFloat(replace(reqs['memory'], 'Mi', ''))\n    WHEN reqs['memory'] ENDS WITH 'Ki' THEN toFloat(replace(reqs['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(reqs['memory'])\n  END AS req_memory_mib\nRETURN ns['metadata']['name'] AS namespace,\n       SUM(req_memory_mib) AS total_requested_memory_mib,\n       SUM(lim_memory_mib) AS total_limit_memory_mib\nORDER BY total_requested_memory_mib DESC", "rows": 24}, "metrics": {"attempts": 1, "latency_ms": 13911, "total_tokens": 17889, "total_prompt_tokens": 17353, "total_output_tokens": 536}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h04", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'default'\n  AND NOT EXISTS {\n    MATCH (s)-[:Manages]->(:EndpointSlice)\n  }\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace\nORDER BY service", "tokens": {"prompt": 17345, "output": 133, "total": 17478}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'default'\n  AND NOT EXISTS {\n    MATCH (s)-[:Manages]->(:EndpointSlice)\n  }\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace\nORDER BY service", "rows": 4}, "metrics": {"attempts": 1, "latency_ms": 3754, "total_tokens": 17478, "total_prompt_tokens": 17345, "total_output_tokens": 133}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h05", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ing:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(svc:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN DISTINCT\n  ing['metadata']['name'] AS ingress,\n  svc['metadata']['name'] AS backend_service,\n  COUNT(es) AS endpoint_slices\nORDER BY endpoint_slices DESC, ingress, backend_service", "tokens": {"prompt": 17347, "output": 191, "total": 17538}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ing:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(svc:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN DISTINCT\n  ing['metadata']['name'] AS ingress,\n  svc['metadata']['name'] AS backend_service,\n  COUNT(es) AS endpoint_slices\nORDER BY endpoint_slices DESC, ingress, backend_service", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 5695, "total_tokens": 17538, "total_prompt_tokens": 17347, "total_output_tokens": 191}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h06", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(ing:Ingress)\nWHERE h.name = 'litmus.qa.agoda.is'\nMATCH (ing)-[:DefinesBackend]->(ib:IngressServiceBackend)-[:TargetsService]->(s:Service)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:Endpoint)-[:HasAddress]->(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN h.name AS host,\n       ing['metadata']['namespace'] AS ingress_namespace,\n       ing['metadata']['name'] AS ingress_name,\n       s['metadata']['namespace'] AS service_namespace,\n       s['metadata']['name'] AS service_name,\n       collect(DISTINCT p['metadata']['name']) AS backing_pods\nORDER BY ingress_namespace, ingress_name, service_namespace, service_name", "tokens": {"prompt": 17352, "output": 286, "total": 17638}}], "final": {"valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(ing:Ingress)\nWHERE h.name = 'litmus.qa.agoda.is'\nMATCH (ing)-[:DefinesBackend]->(ib:IngressServiceBackend)-[:TargetsService]->(s:Service)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:Endpoint)-[:HasAddress]->(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN h.name AS host,\n       ing['metadata']['namespace'] AS ingress_namespace,\n       ing['metadata']['name'] AS ingress_name,\n       s['metadata']['namespace'] AS service_namespace,\n       s['metadata']['name'] AS service_name,\n       collect(DISTINCT p['metadata']['name']) AS backing_pods\nORDER BY ingress_namespace, ingress_name, service_namespace, service_name", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 7894, "total_tokens": 17638, "total_prompt_tokens": 17352, "total_output_tokens": 286}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h07", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:Endpoint)\nUNWIND e.addresses AS ip\nWITH s, ip\nWHERE ip IS NOT NULL\nRETURN s.metadata.name AS service_name,\n       s.metadata.namespace AS namespace,\n       COUNT(DISTINCT ip) AS distinct_backing_pod_ips\nORDER BY distinct_backing_pod_ips DESC, namespace, service_name", "tokens": {"prompt": 17345, "output": 189, "total": 17534}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:Endpoint)\nUNWIND e.addresses AS ip\nWITH s, ip\nWHERE ip IS NOT NULL\nRETURN s.metadata.name AS service_name,\n       s.metadata.namespace AS namespace,\n       COUNT(DISTINCT ip) AS distinct_backing_pod_ips\nORDER BY distinct_backing_pod_ips DESC, namespace, service_name", "rows": 102}, "metrics": {"attempts": 1, "latency_ms": 5002, "total_tokens": 17534, "total_prompt_tokens": 17345, "total_output_tokens": 189}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h08", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:Deployment)\nWITH d,\n  coalesce(d['spec']['replicas'], 1) AS desired,\n  coalesce(d['status']['readyReplicas'], 0) AS ready\nWHERE ready < desired\nRETURN\n  d['metadata']['namespace'] AS namespace,\n  d['metadata']['name'] AS deployment,\n  desired AS desired_replicas,\n  ready AS ready_replicas,\n  (desired - ready) AS missing_ready_replicas\nORDER BY missing_ready_replicas DESC, namespace, deployment", "tokens": {"prompt": 17345, "output": 170, "total": 17515}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:Deployment)\nWITH d,\n  coalesce(d['spec']['replicas'], 1) AS desired,\n  coalesce(d['status']['readyReplicas'], 0) AS ready\nWHERE ready < desired\nRETURN\n  d['metadata']['namespace'] AS namespace,\n  d['metadata']['name'] AS deployment,\n  desired AS desired_replicas,\n  ready AS ready_replicas,\n  (desired - ready) AS missing_ready_replicas\nORDER BY missing_ready_replicas DESC, namespace, deployment", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3744, "total_tokens": 17515, "total_prompt_tokens": 17345, "total_output_tokens": 170}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h09", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'storefront'\nMATCH (p:Pod)-[:BelongsTo]->(ns)\nWHERE NOT EXISTS { MATCH (:Deployment)-[:Manages]->(rs:ReplicaSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (:ReplicaSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (:StatefulSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (:DaemonSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (:Job)-[:Manages]->(p) }\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['metadata']['uid'] AS pod_uid,\n       p['status']['phase'] AS phase\nORDER BY pod_name;", "tokens": {"prompt": 17360, "output": 268, "total": 17628}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'storefront'\nMATCH (p:Pod)-[:BelongsTo]->(ns)\nWHERE NOT EXISTS { MATCH (:Deployment)-[:Manages]->(rs:ReplicaSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (:ReplicaSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (:StatefulSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (:DaemonSet)-[:Manages]->(p) }\n  AND NOT EXISTS { MATCH (:Job)-[:Manages]->(p) }\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['metadata']['uid'] AS pod_uid,\n       p['status']['phase'] AS phase\nORDER BY pod_name;", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 5976, "total_tokens": 17628, "total_prompt_tokens": 17360, "total_output_tokens": 268}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h10", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'pyroscope'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nOPTIONAL MATCH (pv)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pvc['metadata']['name'] AS pvc_name,\n  pv['metadata']['name'] AS pv_name,\n  sc['metadata']['name'] AS storage_class_name\nORDER BY pvc_name;", "tokens": {"prompt": 17353, "output": 176, "total": 17529}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'pyroscope'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nOPTIONAL MATCH (pv)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pvc['metadata']['name'] AS pvc_name,\n  pv['metadata']['name'] AS pv_name,\n  sc['metadata']['name'] AS storage_class_name\nORDER BY pvc_name;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 3817, "total_tokens": 17529, "total_prompt_tokens": 17353, "total_output_tokens": 176}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h11", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(s:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH s, count(es) AS endpointSliceCount\nWHERE endpointSliceCount = 0\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace,\n       s['spec']['type'] AS serviceType\nORDER BY service", "tokens": {"prompt": 17346, "output": 169, "total": 17515}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(s:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH s, count(es) AS endpointSliceCount\nWHERE endpointSliceCount = 0\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace,\n       s['spec']['type'] AS serviceType\nORDER BY service", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3905, "total_tokens": 17515, "total_prompt_tokens": 17346, "total_output_tokens": 169}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h12", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (ing:Ingress)-[:BelongsTo]->(ns)\nMATCH (ing)-[:DefinesBackend]->(isb:IngressServiceBackend)\nMATCH (isb)-[:TargetsService]->(svc:Service)\nWHERE NOT EXISTS { MATCH (svc)-[:Manages]->(:EndpointSlice) }\nRETURN \n  ing['metadata']['name'] AS ingress,\n  svc['metadata']['name'] AS backend_service\nORDER BY ingress, backend_service", "tokens": {"prompt": 17351, "output": 174, "total": 17525}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (ing:Ingress)-[:BelongsTo]->(ns)\nMATCH (ing)-[:DefinesBackend]->(isb:IngressServiceBackend)\nMATCH (isb)-[:TargetsService]->(svc:Service)\nWHERE NOT EXISTS { MATCH (svc)-[:Manages]->(:EndpointSlice) }\nRETURN \n  ing['metadata']['name'] AS ingress,\n  svc['metadata']['name'] AS backend_service\nORDER BY ingress, backend_service", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 6494, "total_tokens": 17525, "total_prompt_tokens": 17351, "total_output_tokens": 174}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h13", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND NOT EXISTS { MATCH (pvc)-[:BoundTo]->(:PersistentVolume) }\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['status']['phase'] AS pvc_phase,\n       pvc['spec']['volumeName'] AS spec_volumeName,\n       pvc['spec']['storageClassName'] AS storageClassName\nORDER BY pvc_name", "tokens": {"prompt": 17349, "output": 174, "total": 17523}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND NOT EXISTS { MATCH (pvc)-[:BoundTo]->(:PersistentVolume) }\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['status']['phase'] AS pvc_phase,\n       pvc['spec']['volumeName'] AS spec_volumeName,\n       pvc['spec']['storageClassName'] AS storageClassName\nORDER BY pvc_name", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5179, "total_tokens": 17523, "total_prompt_tokens": 17349, "total_output_tokens": 174}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h14", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (p)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)-[:BoundTo]->(pv:PersistentVolume)\nWHERE pv['spec']['storageClassName'] IS NULL OR pv['spec']['storageClassName'] = ''\nRETURN\n  p['metadata']['name'] AS pod,\n  pvc['metadata']['name'] AS pvc,\n  pv['metadata']['name'] AS pv,\n  pv['spec']['storageClassName'] AS storageClassName\nORDER BY pod, pvc, pv", "tokens": {"prompt": 17351, "output": 208, "total": 17559}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (p)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)-[:BoundTo]->(pv:PersistentVolume)\nWHERE pv['spec']['storageClassName'] IS NULL OR pv['spec']['storageClassName'] = ''\nRETURN\n  p['metadata']['name'] AS pod,\n  pvc['metadata']['name'] AS pvc,\n  pv['metadata']['name'] AS pv,\n  pv['spec']['storageClassName'] AS storageClassName\nORDER BY pod, pvc, pv", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4358, "total_tokens": 17559, "total_prompt_tokens": 17351, "total_output_tokens": 208}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h15", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:RunsOn]->(n:Node)\nWITH n, count(DISTINCT p['metadata']['namespace']) AS distinct_pod_namespaces\nWHERE distinct_pod_namespaces > 1\nRETURN n['metadata']['name'] AS node_name,\n       distinct_pod_namespaces\nORDER BY distinct_pod_namespaces DESC, node_name ASC", "tokens": {"prompt": 17355, "output": 144, "total": 17499}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:RunsOn]->(n:Node)\nWITH n, count(DISTINCT p['metadata']['namespace']) AS distinct_pod_namespaces\nWHERE distinct_pod_namespaces > 1\nRETURN n['metadata']['name'] AS node_name,\n       distinct_pod_namespaces\nORDER BY distinct_pod_namespaces DESC, node_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5195, "total_tokens": 17499, "total_prompt_tokens": 17355, "total_output_tokens": 144}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h16", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (d)-[:Manages]->(rs:ReplicaSet)-[:Manages]->(p:Pod)\nRETURN d['metadata']['name'] AS deployment,\n       COUNT(DISTINCT p) AS managed_pod_count\nORDER BY managed_pod_count DESC, deployment ASC", "tokens": {"prompt": 17351, "output": 165, "total": 17516}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (d)-[:Manages]->(rs:ReplicaSet)-[:Manages]->(p:Pod)\nRETURN d['metadata']['name'] AS deployment,\n       COUNT(DISTINCT p) AS managed_pod_count\nORDER BY managed_pod_count DESC, deployment ASC", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 3911, "total_tokens": 17516, "total_prompt_tokens": 17351, "total_output_tokens": 165}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h17", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nAND EXISTS {\n  MATCH (e:Event)-[:Concerns]->(p)\n  WHERE e['type'] = 'Warning'\n}\nRETURN\n  p['metadata']['name'] AS pod,\n  p['status']['phase'] AS phase\nORDER BY pod", "tokens": {"prompt": 17348, "output": 153, "total": 17501}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nAND EXISTS {\n  MATCH (e:Event)-[:Concerns]->(p)\n  WHERE e['type'] = 'Warning'\n}\nRETURN\n  p['metadata']['name'] AS pod,\n  p['status']['phase'] AS phase\nORDER BY pod", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3251, "total_tokens": 17501, "total_prompt_tokens": 17348, "total_output_tokens": 153}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h18", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nOPTIONAL MATCH (ns)<-[:BelongsTo]-(s:Service)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH ns, s, COUNT(es) AS endpoint_slices_for_service\nWITH ns,\n     SUM(CASE WHEN s IS NOT NULL AND endpoint_slices_for_service = 0 THEN 1 ELSE 0 END) AS services_with_zero_endpoint_slices,\n     COUNT(DISTINCT s) AS total_services\nRETURN ns['metadata']['name'] AS namespace,\n       services_with_zero_endpoint_slices,\n       total_services\nORDER BY services_with_zero_endpoint_slices DESC, total_services DESC, namespace ASC", "tokens": {"prompt": 17345, "output": 221, "total": 17566}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nOPTIONAL MATCH (ns)<-[:BelongsTo]-(s:Service)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH ns, s, COUNT(es) AS endpoint_slices_for_service\nWITH ns,\n     SUM(CASE WHEN s IS NOT NULL AND endpoint_slices_for_service = 0 THEN 1 ELSE 0 END) AS services_with_zero_endpoint_slices,\n     COUNT(DISTINCT s) AS total_services\nRETURN ns['metadata']['name'] AS namespace,\n       services_with_zero_endpoint_slices,\n       total_services\nORDER BY services_with_zero_endpoint_slices DESC, total_services DESC, namespace ASC", "rows": 34}, "metrics": {"attempts": 1, "latency_ms": 4881, "total_tokens": 17566, "total_prompt_tokens": 17345, "total_output_tokens": 221}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h19", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(i:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nRETURN\n  h.name AS host,\n  i['metadata']['namespace'] AS ingress_namespace,\n  i['metadata']['name'] AS ingress_name,\n  b.name AS backend_name,\n  b.port AS backend_port,\n  s['metadata']['namespace'] AS service_namespace,\n  s['metadata']['name'] AS service_name\nORDER BY host, ingress_namespace, ingress_name, service_namespace, service_name", "tokens": {"prompt": 17344, "output": 205, "total": 17549}}], "final": {"valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(i:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nRETURN\n  h.name AS host,\n  i['metadata']['namespace'] AS ingress_namespace,\n  i['metadata']['name'] AS ingress_name,\n  b.name AS backend_name,\n  b.port AS backend_port,\n  s['metadata']['namespace'] AS service_namespace,\n  s['metadata']['name'] AS service_name\nORDER BY host, ingress_namespace, ingress_name, service_namespace, service_name", "rows": 26}, "metrics": {"attempts": 1, "latency_ms": 5063, "total_tokens": 17549, "total_prompt_tokens": 17344, "total_output_tokens": 205}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h20", "run_index": 2, "mode": "retry", "attempts": [{"attempt": 1, "valid": false, "error": "Cypher schema validation failed:\n- Invalid relationship: Endpoint <- EndpointAddress via HasAddress. Allowed: Endpoint -> EndpointAddress. Pattern: (:Endpoint)<-[:HasAddress]-(:EndpointAddress) [rule=script/query/regularQuery/singleQuery/multiPartQ/readingStatement/matchSt/patternWhere/pattern/patternPart/patternElem/patternElemChain/relationshipPattern]\n  Hint: HasAddress is only allowed as Endpoint -> EndpointAddress. Check direction and node labels.", "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(:EndpointSlice)-[:ContainsEndpoint]->(:Endpoint)<-[:HasAddress]-(:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nWITH s, p, coalesce(p['status']['phase'], 'UNKNOWN') AS phase\nRETURN s['metadata']['name'] AS service,\n       phase,\n       count(DISTINCT p) AS pod_count\nORDER BY service, phase", "tokens": {"prompt": 17347, "output": 212, "total": 17559}}, {"attempt": 2, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(:EndpointSlice)-[:ContainsEndpoint]->(:Endpoint)-[:HasAddress]->(:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nWITH s, p, coalesce(p['status']['phase'], 'UNKNOWN') AS phase\nRETURN s['metadata']['name'] AS service,\n       phase,\n       count(DISTINCT p) AS pod_count\nORDER BY service, phase", "tokens": {"prompt": 17602, "output": 201, "total": 17803}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(:EndpointSlice)-[:ContainsEndpoint]->(:Endpoint)-[:HasAddress]->(:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nWITH s, p, coalesce(p['status']['phase'], 'UNKNOWN') AS phase\nRETURN s['metadata']['name'] AS service,\n       phase,\n       count(DISTINCT p) AS pod_count\nORDER BY service, phase", "rows": 5}, "metrics": {"attempts": 2, "latency_ms": 11000, "total_tokens": 35362, "total_prompt_tokens": 34949, "total_output_tokens": 413}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e01", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       n['metadata']['name'] AS namespace\nORDER BY cluster, namespace", "tokens": {"prompt": 17341, "output": 62, "total": 17403}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       n['metadata']['name'] AS namespace\nORDER BY cluster, namespace", "rows": 34}, "metrics": {"attempts": 1, "latency_ms": 2008, "total_tokens": 17403, "total_prompt_tokens": 17341, "total_output_tokens": 62}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e02", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       COUNT(DISTINCT n) AS namespace_count\nORDER BY namespace_count DESC", "tokens": {"prompt": 17343, "output": 92, "total": 17435}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Namespace)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       COUNT(DISTINCT n) AS namespace_count\nORDER BY namespace_count DESC", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 4743, "total_tokens": 17435, "total_prompt_tokens": 17343, "total_output_tokens": 92}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e03", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['status']['phase'] AS phase\nORDER BY pod_name", "tokens": {"prompt": 17342, "output": 91, "total": 17433}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod_name,\n       p['metadata']['namespace'] AS namespace,\n       p['status']['phase'] AS phase\nORDER BY pod_name", "rows": 7}, "metrics": {"attempts": 1, "latency_ms": 3925, "total_tokens": 17433, "total_prompt_tokens": 17342, "total_output_tokens": 91}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e04", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace,\n       s['spec']['type'] AS type,\n       s['spec']['clusterIP'] AS clusterIP\nORDER BY service", "tokens": {"prompt": 17342, "output": 102, "total": 17444}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace,\n       s['spec']['type'] AS type,\n       s['spec']['clusterIP'] AS clusterIP\nORDER BY service", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 3369, "total_tokens": 17444, "total_prompt_tokens": 17342, "total_output_tokens": 102}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e05", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN i['metadata']['name'] AS ingress_name,\n       i['metadata']['namespace'] AS namespace,\n       i['spec']['ingressClassName'] AS ingress_class,\n       i['status']['loadBalancer'] AS load_balancer_status\nORDER BY ingress_name;", "tokens": {"prompt": 17343, "output": 144, "total": 17487}}], "final": {"valid": true, "error": null, "cypher": "MATCH (i:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN i['metadata']['name'] AS ingress_name,\n       i['metadata']['namespace'] AS namespace,\n       i['spec']['ingressClassName'] AS ingress_class,\n       i['status']['loadBalancer'] AS load_balancer_status\nORDER BY ingress_name;", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 4202, "total_tokens": 17487, "total_prompt_tokens": 17343, "total_output_tokens": 144}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e06", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (es:EndpointSlice)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN es['metadata']['name'] AS endpointSlice,\n       es['metadata']['namespace'] AS namespace,\n       es['addressType'] AS addressType,\n       es['metadata']['creationTimestamp'] AS createdAt\nORDER BY endpointSlice;", "tokens": {"prompt": 17343, "output": 151, "total": 17494}}], "final": {"valid": true, "error": null, "cypher": "MATCH (es:EndpointSlice)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN es['metadata']['name'] AS endpointSlice,\n       es['metadata']['namespace'] AS namespace,\n       es['addressType'] AS addressType,\n       es['metadata']['creationTimestamp'] AS createdAt\nORDER BY endpointSlice;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 4027, "total_tokens": 17494, "total_prompt_tokens": 17343, "total_output_tokens": 151}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e07", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)\nRETURN n['metadata']['name'] AS node_name\nORDER BY node_name;", "tokens": {"prompt": 17341, "output": 95, "total": 17436}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)\nRETURN n['metadata']['name'] AS node_name\nORDER BY node_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2982, "total_tokens": 17436, "total_prompt_tokens": 17341, "total_output_tokens": 95}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e08", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (sc:StorageClass)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       sc['metadata']['name'] AS storage_class,\n       sc['provisioner'] AS provisioner,\n       sc['reclaimPolicy'] AS reclaim_policy,\n       sc['volumeBindingMode'] AS volume_binding_mode,\n       sc['allowVolumeExpansion'] AS allow_volume_expansion\nORDER BY cluster, storage_class", "tokens": {"prompt": 17342, "output": 116, "total": 17458}}], "final": {"valid": true, "error": null, "cypher": "MATCH (sc:StorageClass)-[:PartOf]->(c:Cluster)\nRETURN c.name AS cluster,\n       sc['metadata']['name'] AS storage_class,\n       sc['provisioner'] AS provisioner,\n       sc['reclaimPolicy'] AS reclaim_policy,\n       sc['volumeBindingMode'] AS volume_binding_mode,\n       sc['allowVolumeExpansion'] AS allow_volume_expansion\nORDER BY cluster, storage_class", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3403, "total_tokens": 17458, "total_prompt_tokens": 17342, "total_output_tokens": 116}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e09", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:PartOf]->(c:Cluster)\nRETURN\n  c.name AS cluster,\n  pv['metadata']['name'] AS persistent_volume,\n  pv['status']['phase'] AS phase,\n  pv['spec']['storageClassName'] AS storage_class,\n  pv['spec']['capacity'] AS capacity,\n  pv['spec']['accessModes'] AS access_modes,\n  pv['spec']['persistentVolumeReclaimPolicy'] AS reclaim_policy\nORDER BY cluster, persistent_volume;", "tokens": {"prompt": 17342, "output": 169, "total": 17511}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:PartOf]->(c:Cluster)\nRETURN\n  c.name AS cluster,\n  pv['metadata']['name'] AS persistent_volume,\n  pv['status']['phase'] AS phase,\n  pv['spec']['storageClassName'] AS storage_class,\n  pv['spec']['capacity'] AS capacity,\n  pv['spec']['accessModes'] AS access_modes,\n  pv['spec']['persistentVolumeReclaimPolicy'] AS reclaim_policy\nORDER BY cluster, persistent_volume;", "rows": 17}, "metrics": {"attempts": 1, "latency_ms": 4232, "total_tokens": 17511, "total_prompt_tokens": 17342, "total_output_tokens": 169}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e10", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (sa:ServiceAccount)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN sa['metadata']['name'] AS service_account,\n       sa['metadata']['namespace'] AS namespace,\n       sa['metadata']['uid'] AS uid\nORDER BY service_account;", "tokens": {"prompt": 17343, "output": 93, "total": 17436}}], "final": {"valid": true, "error": null, "cypher": "MATCH (sa:ServiceAccount)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN sa['metadata']['name'] AS service_account,\n       sa['metadata']['namespace'] AS namespace,\n       sa['metadata']['uid'] AS uid\nORDER BY service_account;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 3855, "total_tokens": 17436, "total_prompt_tokens": 17343, "total_output_tokens": 93}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e11", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN d['metadata']['name'] AS deployment,\n       d['metadata']['namespace'] AS namespace\nORDER BY deployment", "tokens": {"prompt": 17342, "output": 100, "total": 17442}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN d['metadata']['name'] AS deployment,\n       d['metadata']['namespace'] AS namespace\nORDER BY deployment", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 2478, "total_tokens": 17442, "total_prompt_tokens": 17342, "total_output_tokens": 100}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e12", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (rs:ReplicaSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN rs['metadata']['name'] AS replicaset,\n       rs['metadata']['namespace'] AS namespace,\n       rs['metadata']['uid'] AS uid\nORDER BY replicaset;", "tokens": {"prompt": 17343, "output": 116, "total": 17459}}], "final": {"valid": true, "error": null, "cypher": "MATCH (rs:ReplicaSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN rs['metadata']['name'] AS replicaset,\n       rs['metadata']['namespace'] AS namespace,\n       rs['metadata']['uid'] AS uid\nORDER BY replicaset;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 4171, "total_tokens": 17459, "total_prompt_tokens": 17343, "total_output_tokens": 116}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e13", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ss:StatefulSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ss['metadata']['name'] AS statefulset,\n       ss['metadata']['namespace'] AS namespace,\n       ss['metadata']['uid'] AS uid\nORDER BY statefulset;", "tokens": {"prompt": 17344, "output": 123, "total": 17467}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ss:StatefulSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ss['metadata']['name'] AS statefulset,\n       ss['metadata']['namespace'] AS namespace,\n       ss['metadata']['uid'] AS uid\nORDER BY statefulset;", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 2824, "total_tokens": 17467, "total_prompt_tokens": 17344, "total_output_tokens": 123}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e14", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:DaemonSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN d['metadata']['name'] AS daemonset,\n       d['metadata']['namespace'] AS namespace,\n       d['metadata']['uid'] AS uid\nORDER BY daemonset", "tokens": {"prompt": 17343, "output": 92, "total": 17435}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:DaemonSet)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN d['metadata']['name'] AS daemonset,\n       d['metadata']['namespace'] AS namespace,\n       d['metadata']['uid'] AS uid\nORDER BY daemonset", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2252, "total_tokens": 17435, "total_prompt_tokens": 17343, "total_output_tokens": 92}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e15", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (j:Job)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN j['metadata']['name'] AS job_name,\n       j['metadata']['namespace'] AS namespace,\n       j['status']['active'] AS active,\n       j['status']['succeeded'] AS succeeded,\n       j['status']['failed'] AS failed,\n       j['status']['startTime'] AS start_time,\n       j['status']['completionTime'] AS completion_time\nORDER BY job_name;", "tokens": {"prompt": 17342, "output": 169, "total": 17511}}], "final": {"valid": true, "error": null, "cypher": "MATCH (j:Job)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN j['metadata']['name'] AS job_name,\n       j['metadata']['namespace'] AS namespace,\n       j['status']['active'] AS active,\n       j['status']['succeeded'] AS succeeded,\n       j['status']['failed'] AS failed,\n       j['status']['startTime'] AS start_time,\n       j['status']['completionTime'] AS completion_time\nORDER BY job_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4733, "total_tokens": 17511, "total_prompt_tokens": 17342, "total_output_tokens": 169}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e16", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  pvc['metadata']['name'] AS pvc_name,\n  pvc['metadata']['namespace'] AS namespace,\n  pvc['status']['phase'] AS phase,\n  pvc['spec']['storageClassName'] AS storageClassName,\n  pvc['spec']['volumeName'] AS volumeName,\n  pvc['metadata']['uid'] AS uid\nORDER BY pvc_name;", "tokens": {"prompt": 17344, "output": 183, "total": 17527}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  pvc['metadata']['name'] AS pvc_name,\n  pvc['metadata']['namespace'] AS namespace,\n  pvc['status']['phase'] AS phase,\n  pvc['spec']['storageClassName'] AS storageClassName,\n  pvc['spec']['volumeName'] AS volumeName,\n  pvc['metadata']['uid'] AS uid\nORDER BY pvc_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3577, "total_tokens": 17527, "total_prompt_tokens": 17344, "total_output_tokens": 183}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e17", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN COUNT(p) AS pod_count;", "tokens": {"prompt": 17343, "output": 62, "total": 17405}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN COUNT(p) AS pod_count;", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 5264, "total_tokens": 17405, "total_prompt_tokens": 17343, "total_output_tokens": 62}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e18", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (cm:ConfigMap)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN cm['metadata']['name'] AS configmap_name,\n       cm['metadata']['namespace'] AS namespace,\n       cm['metadata']['uid'] AS uid\nORDER BY configmap_name", "tokens": {"prompt": 17343, "output": 131, "total": 17474}}], "final": {"valid": true, "error": null, "cypher": "MATCH (cm:ConfigMap)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN cm['metadata']['name'] AS configmap_name,\n       cm['metadata']['namespace'] AS namespace,\n       cm['metadata']['uid'] AS uid\nORDER BY configmap_name", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 5189, "total_tokens": 17474, "total_prompt_tokens": 17343, "total_output_tokens": 131}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e19", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": false, "error": "Cypher schema validation failed:\n- Invalid relationship: NetworkPolicy -> Namespace via BelongsTo. Allowed: Deployment -> Namespace; PersistentVolumeClaim -> Namespace; ReplicaSet -> Namespace; Job -> Namespace; Container -> Namespace; DaemonSet -> Namespace; Logs -> Namespace; Service -> Namespace; EndpointSlice -> Namespace; Ingress -> Namespace; Pod -> Namespace; ConfigMap -> Namespace; ServiceAccount -> Namespace; StatefulSet -> Namespace. Pattern: (np:NetworkPolicy)-[:BelongsTo]->(ns:Namespace) [rule=script/query/regularQuery/singleQuery/singlePartQ/readingStatement/matchSt/patternWhere/pattern/patternPart/patternElem/patternElemChain/relationshipPattern]\n  Hint: BelongsTo is only allowed as Deployment -> Namespace; PersistentVolumeClaim -> Namespace; ReplicaSet -> Namespace; Job -> Namespace; Container -> Namespace; DaemonSet -> Namespace; Logs -> Namespace; Service -> Namespace; EndpointSlice -> Namespace; Ingress -> Namespace; Pod -> Namespace; ConfigMap -> Namespace; ServiceAccount -> Namespace; StatefulSet -> Namespace. Check direction and node labels.", "cypher": "MATCH (np:NetworkPolicy)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN np['metadata']['name'] AS network_policy,\n       np['metadata']['namespace'] AS namespace\nORDER BY network_policy;", "tokens": {"prompt": 17343, "output": 124, "total": 17467}}, {"attempt": 2, "valid": true, "error": null, "cypher": "MATCH (np:NetworkPolicy)\nWHERE np['metadata']['namespace'] = 'litmus'\nRETURN np['metadata']['name'] AS network_policy,\n       np['metadata']['namespace'] AS namespace\nORDER BY network_policy;", "tokens": {"prompt": 17664, "output": 100, "total": 17764}}], "final": {"valid": true, "error": null, "cypher": "MATCH (np:NetworkPolicy)\nWHERE np['metadata']['namespace'] = 'litmus'\nRETURN np['metadata']['name'] AS network_policy,\n       np['metadata']['namespace'] AS namespace\nORDER BY network_policy;", "rows": 0}, "metrics": {"attempts": 2, "latency_ms": 8879, "total_tokens": 35231, "total_prompt_tokens": 35007, "total_output_tokens": 224}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "e20", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN c['metadata']['name'] AS container_name,\n       c['pod_name'] AS pod_name,\n       c['container_type'] AS container_type,\n       ns['metadata']['name'] AS namespace\nORDER BY pod_name, container_name", "tokens": {"prompt": 17342, "output": 105, "total": 17447}}], "final": {"valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN c['metadata']['name'] AS container_name,\n       c['pod_name'] AS pod_name,\n       c['container_type'] AS container_type,\n       ns['metadata']['name'] AS namespace\nORDER BY pod_name, container_name", "rows": 9}, "metrics": {"attempts": 1, "latency_ms": 2456, "total_tokens": 17447, "total_prompt_tokens": 17342, "total_output_tokens": 105}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m01", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (d:Deployment)-[:BelongsTo]->(ns)\nMATCH (d)-[:Manages]->(rs:ReplicaSet)\nRETURN d['metadata']['name'] AS deployment,\n       rs['metadata']['name'] AS replica_set\nORDER BY deployment, replica_set", "tokens": {"prompt": 17348, "output": 102, "total": 17450}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (d:Deployment)-[:BelongsTo]->(ns)\nMATCH (d)-[:Manages]->(rs:ReplicaSet)\nRETURN d['metadata']['name'] AS deployment,\n       rs['metadata']['name'] AS replica_set\nORDER BY deployment, replica_set", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 2128, "total_tokens": 17450, "total_prompt_tokens": 17348, "total_output_tokens": 102}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m02", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(rs:ReplicaSet)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  rs['metadata']['name'] AS replicaset,\n  collect(DISTINCT p['metadata']['name']) AS pods\nORDER BY replicaset;", "tokens": {"prompt": 17348, "output": 98, "total": 17446}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(rs:ReplicaSet)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  rs['metadata']['name'] AS replicaset,\n  collect(DISTINCT p['metadata']['name']) AS pods\nORDER BY replicaset;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 5174, "total_tokens": 17446, "total_prompt_tokens": 17348, "total_output_tokens": 98}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m03", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ds:DaemonSet)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ds['metadata']['name'] AS daemonset,\n  p['metadata']['name'] AS pod,\n  p['status']['phase'] AS pod_phase,\n  p['spec']['nodeName'] AS node\nORDER BY daemonset, pod", "tokens": {"prompt": 17348, "output": 119, "total": 17467}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ds:DaemonSet)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  ds['metadata']['name'] AS daemonset,\n  p['metadata']['name'] AS pod,\n  p['status']['phase'] AS pod_phase,\n  p['spec']['nodeName'] AS node\nORDER BY daemonset, pod", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3366, "total_tokens": 17467, "total_prompt_tokens": 17348, "total_output_tokens": 119}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m04", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (ss:StatefulSet)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (ss)-[:Manages]->(p:Pod)\nRETURN\n  ss['metadata']['name'] AS statefulset,\n  collect(DISTINCT p['metadata']['name']) AS managed_pods\nORDER BY statefulset;", "tokens": {"prompt": 17349, "output": 151, "total": 17500}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (ss:StatefulSet)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (ss)-[:Manages]->(p:Pod)\nRETURN\n  ss['metadata']['name'] AS statefulset,\n  collect(DISTINCT p['metadata']['name']) AS managed_pods\nORDER BY statefulset;", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 3859, "total_tokens": 17500, "total_prompt_tokens": 17349, "total_output_tokens": 151}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m05", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(j:Job)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ns['metadata']['name'] AS namespace,\n       j['metadata']['name'] AS job,\n       p['metadata']['name'] AS pod\nORDER BY job, pod", "tokens": {"prompt": 17347, "output": 101, "total": 17448}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(j:Job)-[:Manages]->(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN ns['metadata']['name'] AS namespace,\n       j['metadata']['name'] AS job,\n       p['metadata']['name'] AS pod\nORDER BY job, pod", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2231, "total_tokens": 17448, "total_prompt_tokens": 17347, "total_output_tokens": 101}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m06", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(s:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  s['metadata']['name'] AS service,\n  es['metadata']['name'] AS endpointSlice\nORDER BY service, endpointSlice", "tokens": {"prompt": 17348, "output": 95, "total": 17443}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(s:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  s['metadata']['name'] AS service,\n  es['metadata']['name'] AS endpointSlice\nORDER BY service, endpointSlice", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 4970, "total_tokens": 17443, "total_prompt_tokens": 17348, "total_output_tokens": 95}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m07", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(svc:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (svc)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(ep:Endpoint)-[:HasAddress]->(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN \n  svc['metadata']['name'] AS service,\n  svc['metadata']['namespace'] AS namespace,\n  collect(DISTINCT p['metadata']['name']) AS backing_pods,\n  count(DISTINCT p) AS backing_pod_count\nORDER BY service", "tokens": {"prompt": 17348, "output": 204, "total": 17552}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(svc:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (svc)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(ep:Endpoint)-[:HasAddress]->(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN \n  svc['metadata']['name'] AS service,\n  svc['metadata']['namespace'] AS namespace,\n  collect(DISTINCT p['metadata']['name']) AS backing_pods,\n  count(DISTINCT p) AS backing_pod_count\nORDER BY service", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 5651, "total_tokens": 17552, "total_prompt_tokens": 17348, "total_output_tokens": 204}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m08", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:RunsOn]->(n:Node)\nWHERE n['metadata']['name'] = '<node>' OR n['name'] = '<node>'\nRETURN p['metadata']['namespace'] AS namespace,\n       p['metadata']['name'] AS pod,\n       p['status']['phase'] AS phase,\n       p['spec']['nodeName'] AS nodeName\nORDER BY namespace, pod;", "tokens": {"prompt": 17344, "output": 159, "total": 17503}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:RunsOn]->(n:Node)\nWHERE n['metadata']['name'] = '<node>' OR n['name'] = '<node>'\nRETURN p['metadata']['namespace'] AS namespace,\n       p['metadata']['name'] AS pod,\n       p['status']['phase'] AS phase,\n       p['spec']['nodeName'] AS nodeName\nORDER BY namespace, pod;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 6482, "total_tokens": 17503, "total_prompt_tokens": 17344, "total_output_tokens": 159}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m09", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nRETURN\n  ns['metadata']['name'] AS namespace,\n  pvc['metadata']['name'] AS pvc_name,\n  pvc['status']['phase'] AS pvc_phase,\n  pv['metadata']['name'] AS pv_name,\n  pv['status']['phase'] AS pv_phase,\n  pv['spec']['storageClassName'] AS pv_storageClassName\nORDER BY pvc_name, pv_name;", "tokens": {"prompt": 17351, "output": 186, "total": 17537}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nRETURN\n  ns['metadata']['name'] AS namespace,\n  pvc['metadata']['name'] AS pvc_name,\n  pvc['status']['phase'] AS pvc_phase,\n  pv['metadata']['name'] AS pv_name,\n  pv['status']['phase'] AS pv_phase,\n  pv['spec']['storageClassName'] AS pv_storageClassName\nORDER BY pvc_name, pv_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3453, "total_tokens": 17537, "total_prompt_tokens": 17351, "total_output_tokens": 186}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m10", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod_name,\n       e['reason'] AS reason,\n       e['type'] AS type,\n       e['note'] AS note,\n       e['eventTime'] AS event_time,\n       e['deprecatedFirstTimestamp'] AS first_timestamp,\n       e['deprecatedLastTimestamp'] AS last_timestamp\nORDER BY coalesce(e['eventTime'], e['deprecatedLastTimestamp'], e['deprecatedFirstTimestamp']) DESC,\n         pod_name ASC", "tokens": {"prompt": 17349, "output": 214, "total": 17563}}], "final": {"valid": true, "error": null, "cypher": "MATCH (e:Event)-[:Concerns]->(p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod_name,\n       e['reason'] AS reason,\n       e['type'] AS type,\n       e['note'] AS note,\n       e['eventTime'] AS event_time,\n       e['deprecatedFirstTimestamp'] AS first_timestamp,\n       e['deprecatedLastTimestamp'] AS last_timestamp\nORDER BY coalesce(e['eventTime'], e['deprecatedLastTimestamp'], e['deprecatedFirstTimestamp']) DESC,\n         pod_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4660, "total_tokens": 17563, "total_prompt_tokens": 17349, "total_output_tokens": 214}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m11", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)-[:RunsOn]->(n:Node)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod,\n       n['metadata']['name'] AS node\nORDER BY pod, node", "tokens": {"prompt": 17348, "output": 90, "total": 17438}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)-[:RunsOn]->(n:Node)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod,\n       n['metadata']['name'] AS node\nORDER BY pod, node", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3838, "total_tokens": 17438, "total_prompt_tokens": 17348, "total_output_tokens": 90}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m12", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod,\n       pvc['metadata']['name'] AS pvc\nORDER BY pod, pvc", "tokens": {"prompt": 17348, "output": 93, "total": 17441}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN p['metadata']['name'] AS pod,\n       pvc['metadata']['name'] AS pvc\nORDER BY pod, pvc", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3813, "total_tokens": 17441, "total_prompt_tokens": 17348, "total_output_tokens": 93}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m13", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nMATCH (c)-[:Runs]->(p:Pod)\nRETURN ns.metadata.name AS namespace,\n       p.metadata.name AS pod,\n       c.spec.name AS container,\n       c.container_type AS container_type\nORDER BY pod, container;", "tokens": {"prompt": 17348, "output": 150, "total": 17498}}], "final": {"valid": true, "error": null, "cypher": "MATCH (c:Container)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nMATCH (c)-[:Runs]->(p:Pod)\nRETURN ns.metadata.name AS namespace,\n       p.metadata.name AS pod,\n       c.spec.name AS container,\n       c.container_type AS container_type\nORDER BY pod, container;", "rows": 9}, "metrics": {"attempts": 1, "latency_ms": 3312, "total_tokens": 17498, "total_prompt_tokens": 17348, "total_output_tokens": 150}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m14", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (c:Container)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (c)-[:HasLogs]->(l:Logs)\nRETURN\n  ns['metadata']['name'] AS namespace,\n  c['metadata']['name'] AS container_name,\n  c['pod_name'] AS pod_name,\n  c['container_type'] AS container_type,\n  l['content'] AS logs\nORDER BY pod_name, container_name", "tokens": {"prompt": 17348, "output": 191, "total": 17539}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (c:Container)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (c)-[:HasLogs]->(l:Logs)\nRETURN\n  ns['metadata']['name'] AS namespace,\n  c['metadata']['name'] AS container_name,\n  c['pod_name'] AS pod_name,\n  c['container_type'] AS container_type,\n  l['content'] AS logs\nORDER BY pod_name, container_name", "rows": 9}, "metrics": {"attempts": 1, "latency_ms": 6085, "total_tokens": 17539, "total_prompt_tokens": 17348, "total_output_tokens": 191}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m15", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(i:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  i['metadata']['name'] AS ingress,\n  s['metadata']['name'] AS service\nORDER BY ingress, service;", "tokens": {"prompt": 17348, "output": 104, "total": 17452}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(i:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nWHERE ns['metadata']['name'] = 'litmus'\nRETURN\n  i['metadata']['name'] AS ingress,\n  s['metadata']['name'] AS service\nORDER BY ingress, service;", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 4007, "total_tokens": 17452, "total_prompt_tokens": 17348, "total_output_tokens": 104}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m16", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (es:EndpointSlice)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (es)-[:ContainsEndpoint]->(e:Endpoint)\nUNWIND e['addresses'] AS addr\nWITH es, e, addr\nMATCH (ea:EndpointAddress)-[:ListedIn]->(es)\nWHERE ea['address'] = addr\nOPTIONAL MATCH (ea)-[:IsAddressOf]->(p:Pod)\nRETURN\n  es['metadata']['name'] AS endpointSlice,\n  es['metadata']['namespace'] AS namespace,\n  collect(DISTINCT {\n    endpoint_node: e['hostname'],\n    ip: ea['address'],\n    pod: p['metadata']['name'],\n    pod_namespace: p['metadata']['namespace']\n  }) AS referencedPods\nORDER BY endpointSlice;", "tokens": {"prompt": 17348, "output": 268, "total": 17616}}], "final": {"valid": true, "error": null, "cypher": "MATCH (es:EndpointSlice)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (es)-[:ContainsEndpoint]->(e:Endpoint)\nUNWIND e['addresses'] AS addr\nWITH es, e, addr\nMATCH (ea:EndpointAddress)-[:ListedIn]->(es)\nWHERE ea['address'] = addr\nOPTIONAL MATCH (ea)-[:IsAddressOf]->(p:Pod)\nRETURN\n  es['metadata']['name'] AS endpointSlice,\n  es['metadata']['namespace'] AS namespace,\n  collect(DISTINCT {\n    endpoint_node: e['hostname'],\n    ip: ea['address'],\n    pod: p['metadata']['name'],\n    pod_namespace: p['metadata']['namespace']\n  }) AS referencedPods\nORDER BY endpointSlice;", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 6534, "total_tokens": 17616, "total_prompt_tokens": 17348, "total_output_tokens": 268}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m17", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Namespace)<-[:BelongsTo]-(s:Service)<-[:Concerns]-(e:Event)\nWHERE n['metadata']['name'] = 'litmus'\nRETURN e['eventTime'] AS event_time,\n       e['type'] AS type,\n       e['reason'] AS reason,\n       e['action'] AS action,\n       e['note'] AS note,\n       e['reportingController'] AS reporting_controller,\n       e['reportingInstance'] AS reporting_instance,\n       e['metadata']['name'] AS event_name,\n       s['metadata']['name'] AS service_name,\n       s['metadata']['namespace'] AS namespace\nORDER BY event_time DESC, event_name ASC", "tokens": {"prompt": 17344, "output": 244, "total": 17588}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Namespace)<-[:BelongsTo]-(s:Service)<-[:Concerns]-(e:Event)\nWHERE n['metadata']['name'] = 'litmus'\nRETURN e['eventTime'] AS event_time,\n       e['type'] AS type,\n       e['reason'] AS reason,\n       e['action'] AS action,\n       e['note'] AS note,\n       e['reportingController'] AS reporting_controller,\n       e['reportingInstance'] AS reporting_instance,\n       e['metadata']['name'] AS event_name,\n       s['metadata']['name'] AS service_name,\n       s['metadata']['namespace'] AS namespace\nORDER BY event_time DESC, event_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 6071, "total_tokens": 17588, "total_prompt_tokens": 17344, "total_output_tokens": 244}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m18", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pv['metadata']['name'] AS persistent_volume,\n  pv['spec']['storageClassName'] AS pv_spec_storageClassName,\n  sc['metadata']['name'] AS storage_class\nORDER BY persistent_volume, storage_class;", "tokens": {"prompt": 17344, "output": 129, "total": 17473}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pv:PersistentVolume)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pv['metadata']['name'] AS persistent_volume,\n  pv['spec']['storageClassName'] AS pv_spec_storageClassName,\n  sc['metadata']['name'] AS storage_class\nORDER BY persistent_volume, storage_class;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3380, "total_tokens": 17473, "total_prompt_tokens": 17344, "total_output_tokens": 129}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m19", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nRETURN n['metadata']['name'] AS node_name, COUNT(p) AS pod_count\nORDER BY pod_count DESC, node_name ASC", "tokens": {"prompt": 17345, "output": 105, "total": 17450}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nRETURN n['metadata']['name'] AS node_name, COUNT(p) AS pod_count\nORDER BY pod_count DESC, node_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3208, "total_tokens": 17450, "total_prompt_tokens": 17345, "total_output_tokens": 105}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "m20", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(s) AS service_count\nORDER BY service_count DESC, namespace ASC", "tokens": {"prompt": 17341, "output": 105, "total": 17446}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(s) AS service_count\nORDER BY service_count DESC, namespace ASC", "rows": 20}, "metrics": {"attempts": 1, "latency_ms": 3296, "total_tokens": 17446, "total_prompt_tokens": 17341, "total_output_tokens": 105}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h01", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(p) AS pod_count\nORDER BY pod_count DESC\nLIMIT 5", "tokens": {"prompt": 17351, "output": 109, "total": 17460}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nRETURN ns['metadata']['name'] AS namespace,\n       COUNT(p) AS pod_count\nORDER BY pod_count DESC\nLIMIT 5", "rows": 5}, "metrics": {"attempts": 1, "latency_ms": 4272, "total_tokens": 17460, "total_prompt_tokens": 17351, "total_output_tokens": 109}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h02", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, COUNT(p) AS pod_count\nWHERE pod_count > 50\nRETURN n['metadata']['name'] AS node_name, pod_count\nORDER BY pod_count DESC", "tokens": {"prompt": 17343, "output": 101, "total": 17444}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, COUNT(p) AS pod_count\nWHERE pod_count > 50\nRETURN n['metadata']['name'] AS node_name, pod_count\nORDER BY pod_count DESC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2622, "total_tokens": 17444, "total_prompt_tokens": 17343, "total_output_tokens": 101}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h03", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nUNWIND p['spec']['containers'] AS container\nWITH ns, p, container\nWITH ns,\n  container['resources']['requests'] AS reqs,\n  container['resources']['limits'] AS lims\nWITH ns,\n  CASE\n    WHEN reqs IS NULL OR reqs['memory'] IS NULL THEN 0.0\n    WHEN reqs['memory'] ENDS WITH 'Ti' THEN toFloat(replace(reqs['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN reqs['memory'] ENDS WITH 'Gi' THEN toFloat(replace(reqs['memory'], 'Gi', '')) * 1024\n    WHEN reqs['memory'] ENDS WITH 'Mi' THEN toFloat(replace(reqs['memory'], 'Mi', ''))\n    WHEN reqs['memory'] ENDS WITH 'Ki' THEN toFloat(replace(reqs['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(reqs['memory'])\n  END AS req_memory_mib,\n  CASE\n    WHEN lims IS NULL OR lims['memory'] IS NULL THEN 0.0\n    WHEN lims['memory'] ENDS WITH 'Ti' THEN toFloat(replace(lims['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN lims['memory'] ENDS WITH 'Gi' THEN toFloat(replace(lims['memory'], 'Gi', '')) * 1024\n    WHEN lims['memory'] ENDS WITH 'Mi' THEN toFloat(replace(lims['memory'], 'Mi', ''))\n    WHEN lims['memory'] ENDS WITH 'Ki' THEN toFloat(replace(lims['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(lims['memory'])\n  END AS lim_memory_mib\nRETURN\n  ns['metadata']['name'] AS namespace,\n  SUM(req_memory_mib) AS total_requested_memory_mib,\n  SUM(lim_memory_mib) AS total_limit_memory_mib\nORDER BY total_requested_memory_mib DESC", "tokens": {"prompt": 17353, "output": 559, "total": 17912}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nUNWIND p['spec']['containers'] AS container\nWITH ns, p, container\nWITH ns,\n  container['resources']['requests'] AS reqs,\n  container['resources']['limits'] AS lims\nWITH ns,\n  CASE\n    WHEN reqs IS NULL OR reqs['memory'] IS NULL THEN 0.0\n    WHEN reqs['memory'] ENDS WITH 'Ti' THEN toFloat(replace(reqs['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN reqs['memory'] ENDS WITH 'Gi' THEN toFloat(replace(reqs['memory'], 'Gi', '')) * 1024\n    WHEN reqs['memory'] ENDS WITH 'Mi' THEN toFloat(replace(reqs['memory'], 'Mi', ''))\n    WHEN reqs['memory'] ENDS WITH 'Ki' THEN toFloat(replace(reqs['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(reqs['memory'])\n  END AS req_memory_mib,\n  CASE\n    WHEN lims IS NULL OR lims['memory'] IS NULL THEN 0.0\n    WHEN lims['memory'] ENDS WITH 'Ti' THEN toFloat(replace(lims['memory'], 'Ti', '')) * 1024 * 1024\n    WHEN lims['memory'] ENDS WITH 'Gi' THEN toFloat(replace(lims['memory'], 'Gi', '')) * 1024\n    WHEN lims['memory'] ENDS WITH 'Mi' THEN toFloat(replace(lims['memory'], 'Mi', ''))\n    WHEN lims['memory'] ENDS WITH 'Ki' THEN toFloat(replace(lims['memory'], 'Ki', '')) / 1024\n    ELSE toFloat(lims['memory'])\n  END AS lim_memory_mib\nRETURN\n  ns['metadata']['name'] AS namespace,\n  SUM(req_memory_mib) AS total_requested_memory_mib,\n  SUM(lim_memory_mib) AS total_limit_memory_mib\nORDER BY total_requested_memory_mib DESC", "rows": 24}, "metrics": {"attempts": 1, "latency_ms": 7196, "total_tokens": 17912, "total_prompt_tokens": 17353, "total_output_tokens": 559}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h04", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'default'\n  AND NOT EXISTS { MATCH (s)-[:Manages]->(:EndpointSlice) }\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace\nORDER BY service", "tokens": {"prompt": 17345, "output": 153, "total": 17498}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'default'\n  AND NOT EXISTS { MATCH (s)-[:Manages]->(:EndpointSlice) }\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace\nORDER BY service", "rows": 4}, "metrics": {"attempts": 1, "latency_ms": 9817, "total_tokens": 17498, "total_prompt_tokens": 17345, "total_output_tokens": 153}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h05", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ing:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(svc:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nWITH ing, b, svc, es\nMATCH (es)-[:ContainsEndpoint]->(ep:Endpoint)\nRETURN DISTINCT\n  ing['metadata']['name'] AS ingress,\n  ing['metadata']['namespace'] AS namespace,\n  svc['metadata']['name'] AS service,\n  b['name'] AS backend_service_name,\n  es['metadata']['name'] AS endpointSlice,\n  COUNT(DISTINCT ep) AS endpoints\nORDER BY ingress, service, endpointSlice", "tokens": {"prompt": 17347, "output": 232, "total": 17579}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(ing:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(svc:Service)-[:Manages]->(es:EndpointSlice)\nWHERE ns['metadata']['name'] = 'litmus'\nWITH ing, b, svc, es\nMATCH (es)-[:ContainsEndpoint]->(ep:Endpoint)\nRETURN DISTINCT\n  ing['metadata']['name'] AS ingress,\n  ing['metadata']['namespace'] AS namespace,\n  svc['metadata']['name'] AS service,\n  b['name'] AS backend_service_name,\n  es['metadata']['name'] AS endpointSlice,\n  COUNT(DISTINCT ep) AS endpoints\nORDER BY ingress, service, endpointSlice", "rows": 2}, "metrics": {"attempts": 1, "latency_ms": 8193, "total_tokens": 17579, "total_prompt_tokens": 17347, "total_output_tokens": 232}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h06", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": false, "error": "Cypher schema validation failed:\n- Invalid relationship: Endpoint <- EndpointAddress via HasAddress. Allowed: Endpoint -> EndpointAddress. Pattern: (e)<-[:HasAddress]-(ea:EndpointAddress) [rule=script/query/regularQuery/singleQuery/singlePartQ/readingStatement/matchSt/patternWhere/pattern/patternPart/patternElem/patternElemChain/relationshipPattern]\n  Hint: HasAddress is only allowed as Endpoint -> EndpointAddress. Check direction and node labels.", "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(ing:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nWHERE h.name = 'litmus.qa.agoda.is'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:Endpoint)\nOPTIONAL MATCH (e)<-[:HasAddress]-(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN\n  h.name AS host,\n  ing['metadata']['namespace'] AS ingress_namespace,\n  ing['metadata']['name'] AS ingress_name,\n  s['metadata']['namespace'] AS service_namespace,\n  s['metadata']['name'] AS service_name,\n  collect(DISTINCT {\n    pod_namespace: p['metadata']['namespace'],\n    pod_name: p['metadata']['name'],\n    pod_phase: p['status']['phase'],\n    pod_ip: p['status']['podIP']\n  }) AS backing_pods\nORDER BY ingress_namespace, ingress_name, service_namespace, service_name", "tokens": {"prompt": 17352, "output": 330, "total": 17682}}, {"attempt": 2, "valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(ing:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nWHERE h.name = 'litmus.qa.agoda.is'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:Endpoint)\nOPTIONAL MATCH (e)-[:HasAddress]->(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN\n  h.name AS host,\n  ing['metadata']['namespace'] AS ingress_namespace,\n  ing['metadata']['name'] AS ingress_name,\n  s['metadata']['namespace'] AS service_namespace,\n  s['metadata']['name'] AS service_name,\n  collect(DISTINCT {\n    pod_namespace: p['metadata']['namespace'],\n    pod_name: p['metadata']['name'],\n    pod_phase: p['status']['phase'],\n    pod_ip: p['status']['podIP']\n  }) AS backing_pods\nORDER BY ingress_namespace, ingress_name, service_namespace, service_name", "tokens": {"prompt": 17713, "output": 295, "total": 18008}}], "final": {"valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(ing:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nWHERE h.name = 'litmus.qa.agoda.is'\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:Endpoint)\nOPTIONAL MATCH (e)-[:HasAddress]->(ea:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nRETURN\n  h.name AS host,\n  ing['metadata']['namespace'] AS ingress_namespace,\n  ing['metadata']['name'] AS ingress_name,\n  s['metadata']['namespace'] AS service_namespace,\n  s['metadata']['name'] AS service_name,\n  collect(DISTINCT {\n    pod_namespace: p['metadata']['namespace'],\n    pod_name: p['metadata']['name'],\n    pod_phase: p['status']['phase'],\n    pod_ip: p['status']['podIP']\n  }) AS backing_pods\nORDER BY ingress_namespace, ingress_name, service_namespace, service_name", "rows": 2}, "metrics": {"attempts": 2, "latency_ms": 12647, "total_tokens": 35690, "total_prompt_tokens": 35065, "total_output_tokens": 625}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h07", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": false, "error": "Cypher schema validation failed:\n- Invalid relationship: EndpointSlice -> EndpointSlice via ContainsEndpoint. Allowed: EndpointSlice -> Endpoint. Pattern: (es:EndpointSlice)-[:ContainsEndpoint]->(e:EndpointSlice) [rule=script/query/regularQuery/singleQuery/singlePartQ/readingStatement/matchSt/patternWhere/pattern/patternPart/patternElem/patternElemChain/relationshipPattern]\n  Hint: ContainsEndpoint is only allowed as EndpointSlice -> Endpoint. Check direction and node labels.", "cypher": "MATCH (s:Service)-[:Manages]->(es:EndpointSlice)-[:ContainsEndpoint]->(e:EndpointSlice)\nUNWIND e['endpoints'] AS ep\nWITH s, ep\nWHERE ep['addresses'] IS NOT NULL\nUNWIND ep['addresses'] AS ip\nWITH s, ip\nRETURN s['metadata']['namespace'] AS namespace,\n       s['metadata']['name'] AS service,\n       COUNT(DISTINCT ip) AS distinct_backing_pod_ips\nORDER BY namespace, service", "tokens": {"prompt": 17345, "output": 207, "total": 17552}}, {"attempt": 2, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:Manages]->(es:EndpointSlice)\nMATCH (es)-[:ContainsEndpoint]->(e:Endpoint)\nWITH s, e\nWHERE e['addresses'] IS NOT NULL\nUNWIND e['addresses'] AS ip\nWITH s, ip\nRETURN s['metadata']['namespace'] AS namespace,\n       s['metadata']['name'] AS service,\n       COUNT(DISTINCT ip) AS distinct_backing_pod_ips\nORDER BY namespace, service", "tokens": {"prompt": 17595, "output": 183, "total": 17778}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:Manages]->(es:EndpointSlice)\nMATCH (es)-[:ContainsEndpoint]->(e:Endpoint)\nWITH s, e\nWHERE e['addresses'] IS NOT NULL\nUNWIND e['addresses'] AS ip\nWITH s, ip\nRETURN s['metadata']['namespace'] AS namespace,\n       s['metadata']['name'] AS service,\n       COUNT(DISTINCT ip) AS distinct_backing_pod_ips\nORDER BY namespace, service", "rows": 102}, "metrics": {"attempts": 2, "latency_ms": 9719, "total_tokens": 35330, "total_prompt_tokens": 34940, "total_output_tokens": 390}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h08", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:Deployment)\nWITH d,\n  coalesce(d['spec']['replicas'], 1) AS desired,\n  coalesce(d['status']['readyReplicas'], 0) AS ready\nWHERE ready < desired\nRETURN d['metadata']['namespace'] AS namespace,\n       d['metadata']['name'] AS deployment,\n       desired AS desired_replicas,\n       ready AS ready_replicas,\n       (desired - ready) AS missing_ready\nORDER BY missing_ready DESC, namespace, deployment", "tokens": {"prompt": 17345, "output": 210, "total": 17555}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:Deployment)\nWITH d,\n  coalesce(d['spec']['replicas'], 1) AS desired,\n  coalesce(d['status']['readyReplicas'], 0) AS ready\nWHERE ready < desired\nRETURN d['metadata']['namespace'] AS namespace,\n       d['metadata']['name'] AS deployment,\n       desired AS desired_replicas,\n       ready AS ready_replicas,\n       (desired - ready) AS missing_ready\nORDER BY missing_ready DESC, namespace, deployment", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 4685, "total_tokens": 17555, "total_prompt_tokens": 17345, "total_output_tokens": 210}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h09", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nWHERE ns['metadata']['name'] = 'storefront'\nAND NOT EXISTS { MATCH (:Deployment)-[:Manages]->(:ReplicaSet)-[:Manages]->(p) }\nAND NOT EXISTS { MATCH (:StatefulSet)-[:Manages]->(p) }\nAND NOT EXISTS { MATCH (:DaemonSet)-[:Manages]->(p) }\nAND NOT EXISTS { MATCH (:Job)-[:Manages]->(p) }\nAND NOT EXISTS { MATCH (:ReplicaSet)-[:Manages]->(p) }\nRETURN\n  p['metadata']['name'] AS pod_name,\n  p['metadata']['namespace'] AS namespace,\n  p['metadata']['uid'] AS pod_uid,\n  p['status']['phase'] AS phase,\n  p['spec']['nodeName'] AS node_name\nORDER BY pod_name;", "tokens": {"prompt": 17360, "output": 252, "total": 17612}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nWHERE ns['metadata']['name'] = 'storefront'\nAND NOT EXISTS { MATCH (:Deployment)-[:Manages]->(:ReplicaSet)-[:Manages]->(p) }\nAND NOT EXISTS { MATCH (:StatefulSet)-[:Manages]->(p) }\nAND NOT EXISTS { MATCH (:DaemonSet)-[:Manages]->(p) }\nAND NOT EXISTS { MATCH (:Job)-[:Manages]->(p) }\nAND NOT EXISTS { MATCH (:ReplicaSet)-[:Manages]->(p) }\nRETURN\n  p['metadata']['name'] AS pod_name,\n  p['metadata']['namespace'] AS namespace,\n  p['metadata']['uid'] AS pod_uid,\n  p['status']['phase'] AS phase,\n  p['spec']['nodeName'] AS node_name\nORDER BY pod_name;", "rows": 1}, "metrics": {"attempts": 1, "latency_ms": 5202, "total_tokens": 17612, "total_prompt_tokens": 17360, "total_output_tokens": 252}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h10", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'pyroscope'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nOPTIONAL MATCH (pv)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pvc['metadata']['name'] AS pvc_name,\n  pv['metadata']['name'] AS pv_name,\n  sc['metadata']['name'] AS storage_class\nORDER BY pvc_name;", "tokens": {"prompt": 17353, "output": 168, "total": 17521}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'pyroscope'\nOPTIONAL MATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nOPTIONAL MATCH (pv)-[:UsesStorageClass]->(sc:StorageClass)\nRETURN\n  pvc['metadata']['name'] AS pvc_name,\n  pv['metadata']['name'] AS pv_name,\n  sc['metadata']['name'] AS storage_class\nORDER BY pvc_name;", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 3564, "total_tokens": 17521, "total_prompt_tokens": 17353, "total_output_tokens": 168}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h11", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nWITH s\nWHERE NOT EXISTS { MATCH (s)-[:Manages]->(:EndpointSlice) }\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace\nORDER BY service", "tokens": {"prompt": 17346, "output": 129, "total": 17475}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nWITH s\nWHERE NOT EXISTS { MATCH (s)-[:Manages]->(:EndpointSlice) }\nRETURN s['metadata']['name'] AS service,\n       s['metadata']['namespace'] AS namespace\nORDER BY service", "execution_error": "MemgraphError: QueryError: Query execution error: Not yet implemented: Exists cannot be used within WITH!"}, "metrics": {"attempts": 1, "latency_ms": 2863, "total_tokens": 17475, "total_prompt_tokens": 17346, "total_output_tokens": 129}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h12", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ing:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (ing)-[:DefinesBackend]->(be:IngressServiceBackend)-[:TargetsService]->(svc:Service)\nWHERE NOT EXISTS { MATCH (svc)-[:Manages]->(:EndpointSlice) }\nRETURN ing['metadata']['name'] AS ingress,\n       collect(DISTINCT svc['metadata']['name']) AS backend_services_without_endpoint_slices\nORDER BY ingress", "tokens": {"prompt": 17351, "output": 220, "total": 17571}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ing:Ingress)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (ing)-[:DefinesBackend]->(be:IngressServiceBackend)-[:TargetsService]->(svc:Service)\nWHERE NOT EXISTS { MATCH (svc)-[:Manages]->(:EndpointSlice) }\nRETURN ing['metadata']['name'] AS ingress,\n       collect(DISTINCT svc['metadata']['name']) AS backend_services_without_endpoint_slices\nORDER BY ingress", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5480, "total_tokens": 17571, "total_prompt_tokens": 17351, "total_output_tokens": 220}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h13", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND NOT EXISTS { MATCH (pvc)-[:BoundTo]->(:PersistentVolume) }\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['metadata']['namespace'] AS namespace,\n       pvc['status']['phase'] AS phase,\n       pvc['spec']['volumeName'] AS spec_volumeName\nORDER BY pvc_name;", "tokens": {"prompt": 17349, "output": 174, "total": 17523}}], "final": {"valid": true, "error": null, "cypher": "MATCH (pvc:PersistentVolumeClaim)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND NOT EXISTS { MATCH (pvc)-[:BoundTo]->(:PersistentVolume) }\nRETURN pvc['metadata']['name'] AS pvc_name,\n       pvc['metadata']['namespace'] AS namespace,\n       pvc['status']['phase'] AS phase,\n       pvc['spec']['volumeName'] AS spec_volumeName\nORDER BY pvc_name;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 3455, "total_tokens": 17523, "total_prompt_tokens": 17349, "total_output_tokens": 174}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h14", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (p)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)\nMATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nOPTIONAL MATCH (pv)-[:UsesStorageClass]->(sc:StorageClass)\nWITH p, pvc, pv, sc\nWHERE sc IS NULL\nRETURN p['metadata']['name'] AS pod,\n       pvc['metadata']['name'] AS pvc,\n       pv['metadata']['name'] AS pv\nORDER BY pod, pvc, pv", "tokens": {"prompt": 17351, "output": 219, "total": 17570}}], "final": {"valid": true, "error": null, "cypher": "MATCH (p:Pod)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nMATCH (p)-[:ClaimsVolume]->(pvc:PersistentVolumeClaim)\nMATCH (pvc)-[:BoundTo]->(pv:PersistentVolume)\nOPTIONAL MATCH (pv)-[:UsesStorageClass]->(sc:StorageClass)\nWITH p, pvc, pv, sc\nWHERE sc IS NULL\nRETURN p['metadata']['name'] AS pod,\n       pvc['metadata']['name'] AS pvc,\n       pv['metadata']['name'] AS pv\nORDER BY pod, pvc, pv", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 6150, "total_tokens": 17570, "total_prompt_tokens": 17351, "total_output_tokens": 219}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h15", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, count(DISTINCT p['metadata']['namespace']) AS distinct_pod_namespaces\nWHERE distinct_pod_namespaces > 1\nRETURN n['metadata']['name'] AS node_name,\n       distinct_pod_namespaces\nORDER BY distinct_pod_namespaces DESC, node_name ASC", "tokens": {"prompt": 17355, "output": 132, "total": 17487}}], "final": {"valid": true, "error": null, "cypher": "MATCH (n:Node)<-[:RunsOn]-(p:Pod)\nWITH n, count(DISTINCT p['metadata']['namespace']) AS distinct_pod_namespaces\nWHERE distinct_pod_namespaces > 1\nRETURN n['metadata']['name'] AS node_name,\n       distinct_pod_namespaces\nORDER BY distinct_pod_namespaces DESC, node_name ASC", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 5046, "total_tokens": 17487, "total_prompt_tokens": 17355, "total_output_tokens": 132}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h16", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nMATCH (d)-[:Manages]->(rs:ReplicaSet)-[:Manages]->(p:Pod)\nRETURN d.metadata.name AS deployment,\n       COUNT(DISTINCT p) AS managed_pod_count\nORDER BY managed_pod_count DESC, deployment ASC", "tokens": {"prompt": 17351, "output": 134, "total": 17485}}], "final": {"valid": true, "error": null, "cypher": "MATCH (d:Deployment)-[:BelongsTo]->(ns:Namespace)\nWHERE ns.metadata.name = 'litmus'\nMATCH (d)-[:Manages]->(rs:ReplicaSet)-[:Manages]->(p:Pod)\nRETURN d.metadata.name AS deployment,\n       COUNT(DISTINCT p) AS managed_pod_count\nORDER BY managed_pod_count DESC, deployment ASC", "rows": 3}, "metrics": {"attempts": 1, "latency_ms": 2854, "total_tokens": 17485, "total_prompt_tokens": 17351, "total_output_tokens": 134}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h17", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND EXISTS {\n    MATCH (e:Event)-[:Concerns]->(p)\n    WHERE e['type'] = 'Warning'\n  }\nRETURN p['metadata']['name'] AS pod,\n       p['metadata']['namespace'] AS namespace,\n       p['status']['phase'] AS phase\nORDER BY pod;", "tokens": {"prompt": 17348, "output": 125, "total": 17473}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)<-[:BelongsTo]-(p:Pod)\nWHERE ns['metadata']['name'] = 'litmus'\n  AND EXISTS {\n    MATCH (e:Event)-[:Concerns]->(p)\n    WHERE e['type'] = 'Warning'\n  }\nRETURN p['metadata']['name'] AS pod,\n       p['metadata']['namespace'] AS namespace,\n       p['status']['phase'] AS phase\nORDER BY pod;", "rows": 0}, "metrics": {"attempts": 1, "latency_ms": 2951, "total_tokens": 17473, "total_prompt_tokens": 17348, "total_output_tokens": 125}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h18", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nOPTIONAL MATCH (s:Service)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH ns, s, COUNT(es) AS endpoint_slices\nWITH ns, COUNT(CASE WHEN s IS NOT NULL AND endpoint_slices = 0 THEN 1 END) AS services_with_zero_endpoint_slices\nRETURN ns['metadata']['name'] AS namespace, services_with_zero_endpoint_slices\nORDER BY services_with_zero_endpoint_slices DESC, namespace ASC", "tokens": {"prompt": 17345, "output": 184, "total": 17529}}], "final": {"valid": true, "error": null, "cypher": "MATCH (ns:Namespace)\nOPTIONAL MATCH (s:Service)-[:BelongsTo]->(ns)\nOPTIONAL MATCH (s)-[:Manages]->(es:EndpointSlice)\nWITH ns, s, COUNT(es) AS endpoint_slices\nWITH ns, COUNT(CASE WHEN s IS NOT NULL AND endpoint_slices = 0 THEN 1 END) AS services_with_zero_endpoint_slices\nRETURN ns['metadata']['name'] AS namespace, services_with_zero_endpoint_slices\nORDER BY services_with_zero_endpoint_slices DESC, namespace ASC", "rows": 34}, "metrics": {"attempts": 1, "latency_ms": 6275, "total_tokens": 17529, "total_prompt_tokens": 17345, "total_output_tokens": 184}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h19", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(i:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nRETURN \n  h.name AS host,\n  i.metadata.name AS ingress_name,\n  i.metadata.namespace AS ingress_namespace,\n  b.name AS backend_name,\n  b.port AS backend_port,\n  s.metadata.name AS service_name,\n  s.metadata.namespace AS service_namespace\nORDER BY host, ingress_namespace, ingress_name, service_namespace, service_name", "tokens": {"prompt": 17344, "output": 214, "total": 17558}}], "final": {"valid": true, "error": null, "cypher": "MATCH (h:Host)-[:IsClaimedBy]->(i:Ingress)-[:DefinesBackend]->(b:IngressServiceBackend)-[:TargetsService]->(s:Service)\nRETURN \n  h.name AS host,\n  i.metadata.name AS ingress_name,\n  i.metadata.namespace AS ingress_namespace,\n  b.name AS backend_name,\n  b.port AS backend_port,\n  s.metadata.name AS service_name,\n  s.metadata.namespace AS service_namespace\nORDER BY host, ingress_namespace, ingress_name, service_namespace, service_name", "rows": 26}, "metrics": {"attempts": 1, "latency_ms": 5455, "total_tokens": 17558, "total_prompt_tokens": 17344, "total_output_tokens": 214}}
{"model": "openai/gpt-5.2-2025-12-11", "question_id": "h20", "run_index": 3, "mode": "retry", "attempts": [{"attempt": 1, "valid": false, "error": "Cypher schema validation failed:\n- Invalid relationship: Endpoint <- EndpointAddress via HasAddress. Allowed: Endpoint -> EndpointAddress. Pattern: (:Endpoint)<-[:HasAddress]-(:EndpointAddress) [rule=script/query/regularQuery/singleQuery/multiPartQ/readingStatement/matchSt/patternWhere/pattern/patternPart/patternElem/patternElemChain/relationshipPattern]\n  Hint: HasAddress is only allowed as Endpoint -> EndpointAddress. Check direction and node labels.", "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(:EndpointSlice)-[:ContainsEndpoint]->(:Endpoint)<-[:HasAddress]-(:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nWITH s, p['status']['phase'] AS phase\nRETURN s['metadata']['name'] AS service,\n       phase,\n       COUNT(DISTINCT p) AS pod_count\nORDER BY service, phase", "tokens": {"prompt": 17347, "output": 197, "total": 17544}}, {"attempt": 2, "valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(:EndpointSlice)-[:ContainsEndpoint]->(:Endpoint)-[:HasAddress]->(:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nWITH s, p['status']['phase'] AS phase\nRETURN s['metadata']['name'] AS service,\n       phase,\n       COUNT(DISTINCT p) AS pod_count\nORDER BY service, phase", "tokens": {"prompt": 17595, "output": 182, "total": 17777}}], "final": {"valid": true, "error": null, "cypher": "MATCH (s:Service)-[:BelongsTo]->(ns:Namespace)\nWHERE ns['metadata']['name'] = 'litmus'\nOPTIONAL MATCH (s)-[:Manages]->(:EndpointSlice)-[:ContainsEndpoint]->(:Endpoint)-[:HasAddress]->(:EndpointAddress)-[:IsAddressOf]->(p:Pod)\nWITH s, p['status']['phase'] AS phase\nRETURN s['metadata']['name'] AS service,\n       phase,\n       COUNT(DISTINCT p) AS pod_count\nORDER BY service, phase", "execution_error": "MemgraphError: QueryError: Query execution error: Unbound variable: p."}, "metrics": {"attempts": 2, "latency_ms": 10133, "total_tokens": 35321, "total_prompt_tokens": 34942, "total_output_tokens": 379}}
